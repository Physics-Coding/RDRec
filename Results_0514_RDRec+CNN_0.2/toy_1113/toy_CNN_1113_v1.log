nohup: ignoring input
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Some weights of Solomon were not initialized from the model checkpoint at t5-small and are newly initialized: ['conv1d.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
task_num                                 5
prompt_num                               3
lr                                       0.0005
ratio                                    1:1:1:3
epochs                                   100
batch_size                               64
cuda                                     True
log_interval                             200
checkpoint                               ./checkpoint/toy_1113/
endure_times                             5
exp_len                                  20
negative_num                             99
----------------------------------------ARGUMENTS----------------------------------------
[2025-05-13 18:17:02.428409]: Loading data
[2025-05-13 18:17:13.314098]: Start training
[2025-05-13 18:17:13.314196]: epoch 1
[2025-05-13 18:18:50.770283]: text loss 1.3537 |   200/ 8196 batches
[2025-05-13 18:20:28.529181]: text loss 1.0574 |   400/ 8196 batches
[2025-05-13 18:22:05.328846]: text loss 1.0054 |   600/ 8196 batches
[2025-05-13 18:23:43.612727]: text loss 0.9960 |   800/ 8196 batches
[2025-05-13 18:25:21.458245]: text loss 0.9629 |  1000/ 8196 batches
[2025-05-13 18:26:58.786773]: text loss 0.9692 |  1200/ 8196 batches
[2025-05-13 18:28:37.063882]: text loss 0.9608 |  1400/ 8196 batches
[2025-05-13 18:30:13.924465]: text loss 0.9481 |  1600/ 8196 batches
[2025-05-13 18:31:51.214578]: text loss 0.9441 |  1800/ 8196 batches
[2025-05-13 18:33:27.768834]: text loss 0.9233 |  2000/ 8196 batches
[2025-05-13 18:35:05.502201]: text loss 0.9328 |  2200/ 8196 batches
[2025-05-13 18:36:42.770078]: text loss 0.9370 |  2400/ 8196 batches
[2025-05-13 18:38:19.720334]: text loss 0.9277 |  2600/ 8196 batches
[2025-05-13 18:39:58.065671]: text loss 0.9375 |  2800/ 8196 batches
[2025-05-13 18:41:35.411417]: text loss 0.9238 |  3000/ 8196 batches
[2025-05-13 18:43:12.824202]: text loss 0.9332 |  3200/ 8196 batches
[2025-05-13 18:44:50.000094]: text loss 0.9243 |  3400/ 8196 batches
[2025-05-13 18:46:26.887360]: text loss 0.9130 |  3600/ 8196 batches
[2025-05-13 18:48:04.965834]: text loss 0.9172 |  3800/ 8196 batches
[2025-05-13 18:49:42.415682]: text loss 0.9318 |  4000/ 8196 batches
[2025-05-13 18:51:19.980131]: text loss 0.9144 |  4200/ 8196 batches
[2025-05-13 18:52:58.112952]: text loss 0.9127 |  4400/ 8196 batches
[2025-05-13 18:54:35.688297]: text loss 0.9097 |  4600/ 8196 batches
[2025-05-13 18:56:12.860985]: text loss 0.9142 |  4800/ 8196 batches
[2025-05-13 18:57:49.527988]: text loss 0.9380 |  5000/ 8196 batches
[2025-05-13 18:59:26.505445]: text loss 0.9350 |  5200/ 8196 batches
[2025-05-13 19:01:03.433702]: text loss 0.9084 |  5400/ 8196 batches
[2025-05-13 19:02:40.159832]: text loss 0.9288 |  5600/ 8196 batches
[2025-05-13 19:04:16.704315]: text loss 0.9234 |  5800/ 8196 batches
[2025-05-13 19:05:53.787837]: text loss 0.9063 |  6000/ 8196 batches
[2025-05-13 19:07:31.406718]: text loss 0.9208 |  6200/ 8196 batches
[2025-05-13 19:09:08.179884]: text loss 0.9293 |  6400/ 8196 batches
[2025-05-13 19:10:45.990918]: text loss 0.9211 |  6600/ 8196 batches
[2025-05-13 19:12:22.539340]: text loss 0.9344 |  6800/ 8196 batches
[2025-05-13 19:14:00.633492]: text loss 0.9094 |  7000/ 8196 batches
[2025-05-13 19:15:38.284893]: text loss 0.9345 |  7200/ 8196 batches
[2025-05-13 19:17:16.312661]: text loss 0.9286 |  7400/ 8196 batches
[2025-05-13 19:18:53.274700]: text loss 0.9261 |  7600/ 8196 batches
[2025-05-13 19:20:30.714225]: text loss 0.9284 |  7800/ 8196 batches
[2025-05-13 19:22:08.042623]: text loss 0.9284 |  8000/ 8196 batches
[2025-05-13 19:23:42.793062]: text loss 0.9346 |  8196/ 8196 batches
[2025-05-13 19:23:42.793733]: validation
[2025-05-13 19:23:44.947006]: explanation loss 2.2728
[2025-05-13 19:23:48.804898]: rationale loss 1.3734
[2025-05-13 19:23:57.929161]: sequential loss 2.3780
[2025-05-13 19:24:56.164117]: top-N loss 1.4443
[2025-05-13 19:24:56.619525]: epoch 2
[2025-05-13 19:24:58.625322]: text loss 0.8979 |  8200/ 8196 batches
[2025-05-13 19:26:35.385992]: text loss 0.8902 |  8400/ 8196 batches
[2025-05-13 19:28:13.099234]: text loss 0.8847 |  8600/ 8196 batches
[2025-05-13 19:29:50.677430]: text loss 0.8746 |  8800/ 8196 batches
[2025-05-13 19:31:28.324572]: text loss 0.8816 |  9000/ 8196 batches
[2025-05-13 19:33:05.534907]: text loss 0.8766 |  9200/ 8196 batches
[2025-05-13 19:34:42.694854]: text loss 0.8781 |  9400/ 8196 batches
[2025-05-13 19:36:20.274018]: text loss 0.8694 |  9600/ 8196 batches
[2025-05-13 19:37:57.349766]: text loss 0.8699 |  9800/ 8196 batches
[2025-05-13 19:39:35.000762]: text loss 0.8701 | 10000/ 8196 batches
[2025-05-13 19:41:11.850245]: text loss 0.8798 | 10200/ 8196 batches
[2025-05-13 19:42:48.869875]: text loss 0.8628 | 10400/ 8196 batches
[2025-05-13 19:44:25.941948]: text loss 0.8779 | 10600/ 8196 batches
[2025-05-13 19:46:02.508757]: text loss 0.8707 | 10800/ 8196 batches
[2025-05-13 19:47:40.043484]: text loss 0.8693 | 11000/ 8196 batches
[2025-05-13 19:49:17.959579]: text loss 0.8644 | 11200/ 8196 batches
[2025-05-13 19:50:55.660028]: text loss 0.8679 | 11400/ 8196 batches
[2025-05-13 19:52:33.248628]: text loss 0.8720 | 11600/ 8196 batches
[2025-05-13 19:54:10.596380]: text loss 0.8610 | 11800/ 8196 batches
[2025-05-13 19:55:49.264804]: text loss 0.8735 | 12000/ 8196 batches
[2025-05-13 19:57:27.775995]: text loss 0.8664 | 12200/ 8196 batches
[2025-05-13 19:59:06.194276]: text loss 0.8657 | 12400/ 8196 batches
[2025-05-13 20:00:42.571198]: text loss 0.8592 | 12600/ 8196 batches
[2025-05-13 20:02:20.123729]: text loss 0.8606 | 12800/ 8196 batches
[2025-05-13 20:03:57.676595]: text loss 0.8650 | 13000/ 8196 batches
[2025-05-13 20:05:34.663961]: text loss 0.8661 | 13200/ 8196 batches
[2025-05-13 20:07:11.769631]: text loss 0.8656 | 13400/ 8196 batches
[2025-05-13 20:08:49.843890]: text loss 0.8615 | 13600/ 8196 batches
[2025-05-13 20:10:25.871388]: text loss 0.8595 | 13800/ 8196 batches
[2025-05-13 20:12:02.219381]: text loss 0.8639 | 14000/ 8196 batches
[2025-05-13 20:13:40.494866]: text loss 0.8578 | 14200/ 8196 batches
[2025-05-13 20:15:18.012878]: text loss 0.8617 | 14400/ 8196 batches
[2025-05-13 20:16:55.340105]: text loss 0.8621 | 14600/ 8196 batches
[2025-05-13 20:18:33.339668]: text loss 0.8560 | 14800/ 8196 batches
[2025-05-13 20:20:10.230883]: text loss 0.8538 | 15000/ 8196 batches
[2025-05-13 20:21:46.677084]: text loss 0.8574 | 15200/ 8196 batches
[2025-05-13 20:23:23.709802]: text loss 0.8543 | 15400/ 8196 batches
[2025-05-13 20:25:00.454512]: text loss 0.8519 | 15600/ 8196 batches
[2025-05-13 20:26:38.370022]: text loss 0.8603 | 15800/ 8196 batches
[2025-05-13 20:28:14.994724]: text loss 0.8517 | 16000/ 8196 batches
[2025-05-13 20:29:52.317288]: text loss 0.8526 | 16200/ 8196 batches
[2025-05-13 20:31:25.802208]: text loss 0.8452 | 16392/ 8196 batches
[2025-05-13 20:31:25.802889]: validation
[2025-05-13 20:31:27.958687]: explanation loss 2.2124
[2025-05-13 20:31:31.809339]: rationale loss 1.3109
[2025-05-13 20:31:40.801014]: sequential loss 2.3151
[2025-05-13 20:32:38.738161]: top-N loss 1.3885
[2025-05-13 20:32:39.131039]: epoch 3
[2025-05-13 20:32:43.015489]: text loss 0.9013 | 16400/ 8196 batches
[2025-05-13 20:34:20.356637]: text loss 0.8399 | 16600/ 8196 batches
[2025-05-13 20:35:57.081771]: text loss 0.8376 | 16800/ 8196 batches
[2025-05-13 20:37:33.343854]: text loss 0.8423 | 17000/ 8196 batches
[2025-05-13 20:39:11.168771]: text loss 0.8360 | 17200/ 8196 batches
[2025-05-13 20:40:49.105260]: text loss 0.8439 | 17400/ 8196 batches
[2025-05-13 20:42:26.329867]: text loss 0.8420 | 17600/ 8196 batches
[2025-05-13 20:44:03.955446]: text loss 0.8435 | 17800/ 8196 batches
[2025-05-13 20:45:42.055347]: text loss 0.8333 | 18000/ 8196 batches
[2025-05-13 20:47:19.701897]: text loss 0.8428 | 18200/ 8196 batches
[2025-05-13 20:48:58.311562]: text loss 0.8427 | 18400/ 8196 batches
[2025-05-13 20:50:36.146279]: text loss 0.8345 | 18600/ 8196 batches
[2025-05-13 20:52:14.227385]: text loss 0.8351 | 18800/ 8196 batches
[2025-05-13 20:53:51.544662]: text loss 0.8321 | 19000/ 8196 batches
[2025-05-13 20:55:28.368936]: text loss 0.8282 | 19200/ 8196 batches
[2025-05-13 20:57:05.265454]: text loss 0.8409 | 19400/ 8196 batches
[2025-05-13 20:58:43.511038]: text loss 0.8377 | 19600/ 8196 batches
[2025-05-13 21:00:20.104247]: text loss 0.8436 | 19800/ 8196 batches
[2025-05-13 21:01:56.231060]: text loss 0.8434 | 20000/ 8196 batches
[2025-05-13 21:03:34.142672]: text loss 0.8277 | 20200/ 8196 batches
[2025-05-13 21:05:10.979511]: text loss 0.8373 | 20400/ 8196 batches
[2025-05-13 21:06:48.949128]: text loss 0.8358 | 20600/ 8196 batches
[2025-05-13 21:08:26.344977]: text loss 0.8418 | 20800/ 8196 batches
[2025-05-13 21:10:03.388290]: text loss 0.8397 | 21000/ 8196 batches
[2025-05-13 21:11:41.106077]: text loss 0.8454 | 21200/ 8196 batches
[2025-05-13 21:13:18.114777]: text loss 0.8296 | 21400/ 8196 batches
[2025-05-13 21:14:55.069684]: text loss 0.8228 | 21600/ 8196 batches
[2025-05-13 21:16:33.630108]: text loss 0.8369 | 21800/ 8196 batches
[2025-05-13 21:18:11.338968]: text loss 0.8281 | 22000/ 8196 batches
[2025-05-13 21:19:48.844313]: text loss 0.8401 | 22200/ 8196 batches
[2025-05-13 21:21:26.172246]: text loss 0.8319 | 22400/ 8196 batches
[2025-05-13 21:23:03.157183]: text loss 0.8345 | 22600/ 8196 batches
[2025-05-13 21:24:39.494027]: text loss 0.8323 | 22800/ 8196 batches
[2025-05-13 21:26:16.204476]: text loss 0.8280 | 23000/ 8196 batches
[2025-05-13 21:27:53.353419]: text loss 0.8295 | 23200/ 8196 batches
[2025-05-13 21:29:30.486235]: text loss 0.8341 | 23400/ 8196 batches
[2025-05-13 21:31:07.505844]: text loss 0.8252 | 23600/ 8196 batches
[2025-05-13 21:32:44.825628]: text loss 0.8315 | 23800/ 8196 batches
[2025-05-13 21:34:21.366197]: text loss 0.8271 | 24000/ 8196 batches
[2025-05-13 21:35:57.979626]: text loss 0.8364 | 24200/ 8196 batches
[2025-05-13 21:37:36.013728]: text loss 0.8363 | 24400/ 8196 batches
[2025-05-13 21:39:07.309421]: text loss 0.8346 | 24588/ 8196 batches
[2025-05-13 21:39:07.310110]: validation
[2025-05-13 21:39:09.443067]: explanation loss 2.1902
[2025-05-13 21:39:13.297803]: rationale loss 1.2815
[2025-05-13 21:39:22.433297]: sequential loss 2.3073
[2025-05-13 21:40:20.711003]: top-N loss 1.3197
[2025-05-13 21:40:21.124363]: epoch 4
[2025-05-13 21:40:27.032331]: text loss 0.8326 | 24600/ 8196 batches
[2025-05-13 21:42:03.270163]: text loss 0.8220 | 24800/ 8196 batches
[2025-05-13 21:43:40.689487]: text loss 0.8141 | 25000/ 8196 batches
[2025-05-13 21:45:17.447884]: text loss 0.8195 | 25200/ 8196 batches
[2025-05-13 21:46:54.191127]: text loss 0.8150 | 25400/ 8196 batches
[2025-05-13 21:48:31.676401]: text loss 0.8105 | 25600/ 8196 batches
[2025-05-13 21:50:08.165797]: text loss 0.8090 | 25800/ 8196 batches
[2025-05-13 21:51:45.847307]: text loss 0.8209 | 26000/ 8196 batches
[2025-05-13 21:53:23.279908]: text loss 0.8218 | 26200/ 8196 batches
[2025-05-13 21:55:00.397990]: text loss 0.8060 | 26400/ 8196 batches
[2025-05-13 21:56:37.683400]: text loss 0.8199 | 26600/ 8196 batches
[2025-05-13 21:58:14.665373]: text loss 0.8192 | 26800/ 8196 batches
[2025-05-13 21:59:51.603860]: text loss 0.8147 | 27000/ 8196 batches
[2025-05-13 22:01:28.458520]: text loss 0.8179 | 27200/ 8196 batches
[2025-05-13 22:03:05.378734]: text loss 0.8195 | 27400/ 8196 batches
[2025-05-13 22:04:43.328750]: text loss 0.8072 | 27600/ 8196 batches
[2025-05-13 22:06:21.274443]: text loss 0.8099 | 27800/ 8196 batches
[2025-05-13 22:07:58.405807]: text loss 0.8093 | 28000/ 8196 batches
[2025-05-13 22:09:35.481097]: text loss 0.8155 | 28200/ 8196 batches
[2025-05-13 22:11:12.070354]: text loss 0.8179 | 28400/ 8196 batches
[2025-05-13 22:12:48.780989]: text loss 0.8157 | 28600/ 8196 batches
[2025-05-13 22:14:25.462998]: text loss 0.8073 | 28800/ 8196 batches
[2025-05-13 22:16:02.161990]: text loss 0.8114 | 29000/ 8196 batches
[2025-05-13 22:17:38.652827]: text loss 0.8138 | 29200/ 8196 batches
[2025-05-13 22:19:15.537612]: text loss 0.8118 | 29400/ 8196 batches
[2025-05-13 22:20:53.055018]: text loss 0.8085 | 29600/ 8196 batches
[2025-05-13 22:22:30.142323]: text loss 0.8146 | 29800/ 8196 batches
[2025-05-13 22:24:08.794412]: text loss 0.8208 | 30000/ 8196 batches
[2025-05-13 22:25:52.143054]: text loss 0.8121 | 30200/ 8196 batches
[2025-05-13 22:27:35.340692]: text loss 0.8167 | 30400/ 8196 batches
[2025-05-13 22:29:12.487801]: text loss 0.8197 | 30600/ 8196 batches
[2025-05-13 22:30:49.404752]: text loss 0.8147 | 30800/ 8196 batches
[2025-05-13 22:32:28.060995]: text loss 0.8089 | 31000/ 8196 batches
[2025-05-13 22:34:06.257056]: text loss 0.8124 | 31200/ 8196 batches
[2025-05-13 22:35:42.770911]: text loss 0.8253 | 31400/ 8196 batches
[2025-05-13 22:37:20.195046]: text loss 0.8193 | 31600/ 8196 batches
[2025-05-13 22:38:57.689399]: text loss 0.8118 | 31800/ 8196 batches
[2025-05-13 22:40:36.200596]: text loss 0.8104 | 32000/ 8196 batches
[2025-05-13 22:42:13.330208]: text loss 0.8194 | 32200/ 8196 batches
[2025-05-13 22:43:50.901931]: text loss 0.8122 | 32400/ 8196 batches
[2025-05-13 22:45:27.425290]: text loss 0.8085 | 32600/ 8196 batches
[2025-05-13 22:46:56.196303]: text loss 0.8112 | 32784/ 8196 batches
[2025-05-13 22:46:56.197373]: validation
[2025-05-13 22:46:58.358838]: explanation loss 2.1384
[2025-05-13 22:47:02.235151]: rationale loss 1.2657
[2025-05-13 22:47:11.278348]: sequential loss 2.2878
[2025-05-13 22:48:09.836794]: top-N loss 1.2935
[2025-05-13 22:48:10.266982]: epoch 5
[2025-05-13 22:48:18.056216]: text loss 0.7936 | 32800/ 8196 batches
[2025-05-13 22:49:54.608106]: text loss 0.7945 | 33000/ 8196 batches
[2025-05-13 22:51:30.789767]: text loss 0.8041 | 33200/ 8196 batches
[2025-05-13 22:53:08.498783]: text loss 0.8013 | 33400/ 8196 batches
[2025-05-13 22:54:45.202967]: text loss 0.8029 | 33600/ 8196 batches
[2025-05-13 22:56:21.804772]: text loss 0.7926 | 33800/ 8196 batches
[2025-05-13 22:57:59.315415]: text loss 0.7958 | 34000/ 8196 batches
[2025-05-13 22:59:36.206259]: text loss 0.8008 | 34200/ 8196 batches
[2025-05-13 23:01:12.979694]: text loss 0.7918 | 34400/ 8196 batches
[2025-05-13 23:02:50.167047]: text loss 0.8013 | 34600/ 8196 batches
[2025-05-13 23:04:27.303155]: text loss 0.7921 | 34800/ 8196 batches
[2025-05-13 23:06:03.537237]: text loss 0.7960 | 35000/ 8196 batches
[2025-05-13 23:07:41.029590]: text loss 0.7999 | 35200/ 8196 batches
[2025-05-13 23:09:18.229204]: text loss 0.8124 | 35400/ 8196 batches
[2025-05-13 23:10:55.533348]: text loss 0.8003 | 35600/ 8196 batches
[2025-05-13 23:12:33.213497]: text loss 0.7942 | 35800/ 8196 batches
[2025-05-13 23:14:10.402688]: text loss 0.7972 | 36000/ 8196 batches
[2025-05-13 23:15:48.857367]: text loss 0.8033 | 36200/ 8196 batches
[2025-05-13 23:17:26.074679]: text loss 0.8042 | 36400/ 8196 batches
[2025-05-13 23:19:02.597289]: text loss 0.7939 | 36600/ 8196 batches
[2025-05-13 23:20:40.052676]: text loss 0.8060 | 36800/ 8196 batches
[2025-05-13 23:22:17.491098]: text loss 0.8111 | 37000/ 8196 batches
[2025-05-13 23:23:54.657723]: text loss 0.7925 | 37200/ 8196 batches
[2025-05-13 23:25:31.687860]: text loss 0.8014 | 37400/ 8196 batches
[2025-05-13 23:27:08.992731]: text loss 0.8029 | 37600/ 8196 batches
[2025-05-13 23:28:45.820540]: text loss 0.7976 | 37800/ 8196 batches
[2025-05-13 23:30:22.790420]: text loss 0.7945 | 38000/ 8196 batches
[2025-05-13 23:31:58.798256]: text loss 0.7956 | 38200/ 8196 batches
[2025-05-13 23:33:36.068518]: text loss 0.8077 | 38400/ 8196 batches
[2025-05-13 23:35:13.016012]: text loss 0.8022 | 38600/ 8196 batches
[2025-05-13 23:36:49.887773]: text loss 0.7978 | 38800/ 8196 batches
[2025-05-13 23:38:27.427231]: text loss 0.7922 | 39000/ 8196 batches
[2025-05-13 23:40:04.627595]: text loss 0.7998 | 39200/ 8196 batches
[2025-05-13 23:41:41.353727]: text loss 0.7994 | 39400/ 8196 batches
[2025-05-13 23:43:19.200541]: text loss 0.7928 | 39600/ 8196 batches
[2025-05-13 23:44:56.643419]: text loss 0.7984 | 39800/ 8196 batches
[2025-05-13 23:46:33.341586]: text loss 0.8044 | 40000/ 8196 batches
[2025-05-13 23:48:10.495799]: text loss 0.8093 | 40200/ 8196 batches
[2025-05-13 23:49:48.814873]: text loss 0.7997 | 40400/ 8196 batches
[2025-05-13 23:51:26.565629]: text loss 0.7939 | 40600/ 8196 batches
[2025-05-13 23:53:03.589769]: text loss 0.7939 | 40800/ 8196 batches
[2025-05-13 23:54:31.815982]: text loss 0.7962 | 40980/ 8196 batches
[2025-05-13 23:54:31.816614]: validation
[2025-05-13 23:54:33.944544]: explanation loss 2.1331
[2025-05-13 23:54:37.795766]: rationale loss 1.2606
[2025-05-13 23:54:46.806990]: sequential loss 2.2804
[2025-05-13 23:55:45.256835]: top-N loss 1.2672
[2025-05-13 23:55:45.654112]: epoch 6
[2025-05-13 23:55:55.289152]: text loss 0.7776 | 41000/ 8196 batches
[2025-05-13 23:57:32.448601]: text loss 0.7856 | 41200/ 8196 batches
[2025-05-13 23:59:10.949644]: text loss 0.7756 | 41400/ 8196 batches
[2025-05-14 00:00:49.146980]: text loss 0.7878 | 41600/ 8196 batches
[2025-05-14 00:02:26.599704]: text loss 0.7879 | 41800/ 8196 batches
[2025-05-14 00:04:03.361239]: text loss 0.7885 | 42000/ 8196 batches
[2025-05-14 00:05:41.719029]: text loss 0.7907 | 42200/ 8196 batches
[2025-05-14 00:07:20.684674]: text loss 0.7907 | 42400/ 8196 batches
[2025-05-14 00:08:58.218437]: text loss 0.7870 | 42600/ 8196 batches
[2025-05-14 00:10:34.696649]: text loss 0.7857 | 42800/ 8196 batches
[2025-05-14 00:12:11.339427]: text loss 0.7899 | 43000/ 8196 batches
[2025-05-14 00:13:49.053378]: text loss 0.7804 | 43200/ 8196 batches
[2025-05-14 00:15:26.917476]: text loss 0.7890 | 43400/ 8196 batches
[2025-05-14 00:17:04.474738]: text loss 0.7825 | 43600/ 8196 batches
[2025-05-14 00:18:40.941732]: text loss 0.7845 | 43800/ 8196 batches
[2025-05-14 00:20:18.085383]: text loss 0.7794 | 44000/ 8196 batches
[2025-05-14 00:21:55.124169]: text loss 0.7865 | 44200/ 8196 batches
[2025-05-14 00:23:32.022671]: text loss 0.7851 | 44400/ 8196 batches
[2025-05-14 00:25:08.772820]: text loss 0.7831 | 44600/ 8196 batches
[2025-05-14 00:26:45.699817]: text loss 0.7838 | 44800/ 8196 batches
[2025-05-14 00:28:22.714217]: text loss 0.7899 | 45000/ 8196 batches
[2025-05-14 00:29:59.340951]: text loss 0.7838 | 45200/ 8196 batches
[2025-05-14 00:31:36.161456]: text loss 0.7890 | 45400/ 8196 batches
[2025-05-14 00:33:12.705988]: text loss 0.7855 | 45600/ 8196 batches
[2025-05-14 00:34:49.284252]: text loss 0.7874 | 45800/ 8196 batches
[2025-05-14 00:36:26.180774]: text loss 0.7867 | 46000/ 8196 batches
[2025-05-14 00:38:02.729194]: text loss 0.7860 | 46200/ 8196 batches
[2025-05-14 00:39:39.066220]: text loss 0.7877 | 46400/ 8196 batches
[2025-05-14 00:41:15.817006]: text loss 0.7942 | 46600/ 8196 batches
[2025-05-14 00:42:53.455705]: text loss 0.7803 | 46800/ 8196 batches
[2025-05-14 00:44:31.893615]: text loss 0.7941 | 47000/ 8196 batches
[2025-05-14 00:46:09.167694]: text loss 0.7907 | 47200/ 8196 batches
[2025-05-14 00:47:46.247537]: text loss 0.7905 | 47400/ 8196 batches
[2025-05-14 00:49:23.391200]: text loss 0.7938 | 47600/ 8196 batches
[2025-05-14 00:51:00.165855]: text loss 0.7891 | 47800/ 8196 batches
[2025-05-14 00:52:36.756264]: text loss 0.7929 | 48000/ 8196 batches
[2025-05-14 00:54:14.005126]: text loss 0.7826 | 48200/ 8196 batches
[2025-05-14 00:55:50.979072]: text loss 0.7891 | 48400/ 8196 batches
[2025-05-14 00:57:27.450563]: text loss 0.7883 | 48600/ 8196 batches
[2025-05-14 00:59:04.034147]: text loss 0.7832 | 48800/ 8196 batches
[2025-05-14 01:00:40.176304]: text loss 0.7871 | 49000/ 8196 batches
[2025-05-14 01:02:05.422503]: text loss 0.7927 | 49176/ 8196 batches
[2025-05-14 01:02:05.423301]: validation
[2025-05-14 01:02:07.548809]: explanation loss 2.1260
[2025-05-14 01:02:11.413203]: rationale loss 1.2627
[2025-05-14 01:02:20.426836]: sequential loss 2.2565
[2025-05-14 01:03:18.558375]: top-N loss 1.2529
[2025-05-14 01:03:18.989100]: epoch 7
[2025-05-14 01:03:30.551378]: text loss 0.7708 | 49200/ 8196 batches
[2025-05-14 01:05:07.737306]: text loss 0.7751 | 49400/ 8196 batches
[2025-05-14 01:06:44.361410]: text loss 0.7700 | 49600/ 8196 batches
[2025-05-14 01:08:21.086973]: text loss 0.7749 | 49800/ 8196 batches
[2025-05-14 01:09:57.444343]: text loss 0.7845 | 50000/ 8196 batches
[2025-05-14 01:11:34.306061]: text loss 0.7749 | 50200/ 8196 batches
[2025-05-14 01:13:11.661569]: text loss 0.7664 | 50400/ 8196 batches
[2025-05-14 01:14:49.627626]: text loss 0.7771 | 50600/ 8196 batches
[2025-05-14 01:16:27.893101]: text loss 0.7779 | 50800/ 8196 batches
[2025-05-14 01:18:04.662653]: text loss 0.7727 | 51000/ 8196 batches
[2025-05-14 01:19:42.947573]: text loss 0.7699 | 51200/ 8196 batches
[2025-05-14 01:21:20.512619]: text loss 0.7712 | 51400/ 8196 batches
[2025-05-14 01:22:58.420306]: text loss 0.7778 | 51600/ 8196 batches
[2025-05-14 01:24:36.732425]: text loss 0.7755 | 51800/ 8196 batches
[2025-05-14 01:26:13.999016]: text loss 0.7819 | 52000/ 8196 batches
[2025-05-14 01:27:52.221090]: text loss 0.7691 | 52200/ 8196 batches
[2025-05-14 01:29:31.079526]: text loss 0.7788 | 52400/ 8196 batches
[2025-05-14 01:31:09.949162]: text loss 0.7755 | 52600/ 8196 batches
[2025-05-14 01:32:47.948357]: text loss 0.7768 | 52800/ 8196 batches
[2025-05-14 01:34:26.125243]: text loss 0.7741 | 53000/ 8196 batches
[2025-05-14 01:36:02.637127]: text loss 0.7702 | 53200/ 8196 batches
[2025-05-14 01:37:39.039323]: text loss 0.7670 | 53400/ 8196 batches
[2025-05-14 01:39:17.207620]: text loss 0.7675 | 53600/ 8196 batches
[2025-05-14 01:40:53.800525]: text loss 0.7766 | 53800/ 8196 batches
[2025-05-14 01:42:31.806315]: text loss 0.7772 | 54000/ 8196 batches
[2025-05-14 01:44:10.053290]: text loss 0.7760 | 54200/ 8196 batches
[2025-05-14 01:45:48.658879]: text loss 0.7806 | 54400/ 8196 batches
[2025-05-14 01:47:27.005209]: text loss 0.7766 | 54600/ 8196 batches
[2025-05-14 01:49:05.328207]: text loss 0.7819 | 54800/ 8196 batches
[2025-05-14 01:50:43.820851]: text loss 0.7686 | 55000/ 8196 batches
[2025-05-14 01:52:20.575260]: text loss 0.7733 | 55200/ 8196 batches
[2025-05-14 01:53:56.277293]: text loss 0.7700 | 55400/ 8196 batches
[2025-05-14 01:55:34.449251]: text loss 0.7805 | 55600/ 8196 batches
[2025-05-14 01:57:12.674792]: text loss 0.7718 | 55800/ 8196 batches
[2025-05-14 01:58:50.922806]: text loss 0.7880 | 56000/ 8196 batches
[2025-05-14 02:00:29.442593]: text loss 0.7814 | 56200/ 8196 batches
[2025-05-14 02:02:06.392763]: text loss 0.7733 | 56400/ 8196 batches
[2025-05-14 02:03:44.655604]: text loss 0.7733 | 56600/ 8196 batches
[2025-05-14 02:05:22.922780]: text loss 0.7793 | 56800/ 8196 batches
[2025-05-14 02:07:01.153466]: text loss 0.7873 | 57000/ 8196 batches
[2025-05-14 02:08:39.391884]: text loss 0.7798 | 57200/ 8196 batches
[2025-05-14 02:10:03.861214]: text loss 0.7795 | 57372/ 8196 batches
[2025-05-14 02:10:03.861864]: validation
[2025-05-14 02:10:06.002986]: explanation loss 2.1241
[2025-05-14 02:10:09.859930]: rationale loss 1.2486
[2025-05-14 02:10:18.829021]: sequential loss 2.2684
[2025-05-14 02:11:16.470683]: top-N loss 1.2457
[2025-05-14 02:11:16.911126]: epoch 8
[2025-05-14 02:11:30.329590]: text loss 0.7577 | 57400/ 8196 batches
[2025-05-14 02:13:07.284495]: text loss 0.7587 | 57600/ 8196 batches
[2025-05-14 02:14:45.452933]: text loss 0.7581 | 57800/ 8196 batches
[2025-05-14 02:16:23.653263]: text loss 0.7619 | 58000/ 8196 batches
[2025-05-14 02:18:01.526673]: text loss 0.7571 | 58200/ 8196 batches
[2025-05-14 02:19:39.917403]: text loss 0.7625 | 58400/ 8196 batches
[2025-05-14 02:21:18.086534]: text loss 0.7703 | 58600/ 8196 batches
[2025-05-14 02:22:56.277455]: text loss 0.7581 | 58800/ 8196 batches
[2025-05-14 02:24:34.469168]: text loss 0.7626 | 59000/ 8196 batches
[2025-05-14 02:26:12.501227]: text loss 0.7679 | 59200/ 8196 batches
[2025-05-14 02:27:48.556739]: text loss 0.7610 | 59400/ 8196 batches
[2025-05-14 02:29:24.555677]: text loss 0.7601 | 59600/ 8196 batches
[2025-05-14 02:31:02.807701]: text loss 0.7768 | 59800/ 8196 batches
[2025-05-14 02:32:40.978340]: text loss 0.7621 | 60000/ 8196 batches
[2025-05-14 02:34:19.156958]: text loss 0.7694 | 60200/ 8196 batches
[2025-05-14 02:35:57.397027]: text loss 0.7614 | 60400/ 8196 batches
[2025-05-14 02:37:35.699879]: text loss 0.7695 | 60600/ 8196 batches
[2025-05-14 02:39:14.239551]: text loss 0.7737 | 60800/ 8196 batches
[2025-05-14 02:40:49.984510]: text loss 0.7677 | 61000/ 8196 batches
[2025-05-14 02:42:26.747442]: text loss 0.7713 | 61200/ 8196 batches
[2025-05-14 02:44:05.269503]: text loss 0.7628 | 61400/ 8196 batches
[2025-05-14 02:45:43.149321]: text loss 0.7628 | 61600/ 8196 batches
[2025-05-14 02:47:21.304551]: text loss 0.7719 | 61800/ 8196 batches
[2025-05-14 02:48:59.522418]: text loss 0.7634 | 62000/ 8196 batches
[2025-05-14 02:50:37.872965]: text loss 0.7697 | 62200/ 8196 batches
[2025-05-14 02:52:14.668609]: text loss 0.7741 | 62400/ 8196 batches
[2025-05-14 02:53:51.994371]: text loss 0.7686 | 62600/ 8196 batches
[2025-05-14 02:55:27.742052]: text loss 0.7616 | 62800/ 8196 batches
[2025-05-14 02:57:03.740121]: text loss 0.7634 | 63000/ 8196 batches
[2025-05-14 02:58:41.472506]: text loss 0.7672 | 63200/ 8196 batches
[2025-05-14 03:00:19.817112]: text loss 0.7647 | 63400/ 8196 batches
[2025-05-14 03:01:58.014369]: text loss 0.7703 | 63600/ 8196 batches
[2025-05-14 03:03:36.193300]: text loss 0.7719 | 63800/ 8196 batches
[2025-05-14 03:05:14.395917]: text loss 0.7705 | 64000/ 8196 batches
[2025-05-14 03:06:52.740440]: text loss 0.7691 | 64200/ 8196 batches
[2025-05-14 03:08:31.038950]: text loss 0.7709 | 64400/ 8196 batches
[2025-05-14 03:10:09.480229]: text loss 0.7613 | 64600/ 8196 batches
[2025-05-14 03:11:47.811568]: text loss 0.7747 | 64800/ 8196 batches
[2025-05-14 03:13:25.928896]: text loss 0.7667 | 65000/ 8196 batches
[2025-05-14 03:15:04.149558]: text loss 0.7688 | 65200/ 8196 batches
[2025-05-14 03:16:42.481175]: text loss 0.7687 | 65400/ 8196 batches
[2025-05-14 03:18:04.126997]: text loss 0.7670 | 65568/ 8196 batches
[2025-05-14 03:18:04.127526]: validation
[2025-05-14 03:18:06.251811]: explanation loss 2.1267
[2025-05-14 03:18:10.110090]: rationale loss 1.2421
[2025-05-14 03:18:19.089151]: sequential loss 2.2643
[2025-05-14 03:19:16.775185]: top-N loss 1.2328
[2025-05-14 03:19:17.222445]: epoch 9
[2025-05-14 03:19:32.657392]: text loss 0.7638 | 65600/ 8196 batches
[2025-05-14 03:21:09.088435]: text loss 0.7485 | 65800/ 8196 batches
[2025-05-14 03:22:47.287112]: text loss 0.7616 | 66000/ 8196 batches
[2025-05-14 03:24:25.468829]: text loss 0.7530 | 66200/ 8196 batches
[2025-05-14 03:26:03.491291]: text loss 0.7465 | 66400/ 8196 batches
[2025-05-14 03:27:39.866457]: text loss 0.7569 | 66600/ 8196 batches
[2025-05-14 03:29:15.645431]: text loss 0.7533 | 66800/ 8196 batches
[2025-05-14 03:30:51.380537]: text loss 0.7580 | 67000/ 8196 batches
[2025-05-14 03:32:27.000951]: text loss 0.7491 | 67200/ 8196 batches
[2025-05-14 03:34:02.847830]: text loss 0.7513 | 67400/ 8196 batches
[2025-05-14 03:35:38.550374]: text loss 0.7537 | 67600/ 8196 batches
[2025-05-14 03:37:14.521317]: text loss 0.7642 | 67800/ 8196 batches
[2025-05-14 03:38:52.986319]: text loss 0.7558 | 68000/ 8196 batches
[2025-05-14 03:40:31.265097]: text loss 0.7529 | 68200/ 8196 batches
[2025-05-14 03:42:09.534097]: text loss 0.7543 | 68400/ 8196 batches
[2025-05-14 03:43:46.927918]: text loss 0.7583 | 68600/ 8196 batches
[2025-05-14 03:45:24.872034]: text loss 0.7526 | 68800/ 8196 batches
[2025-05-14 03:47:03.054738]: text loss 0.7512 | 69000/ 8196 batches
[2025-05-14 03:48:41.088076]: text loss 0.7593 | 69200/ 8196 batches
[2025-05-14 03:50:19.457868]: text loss 0.7563 | 69400/ 8196 batches
[2025-05-14 03:51:57.754252]: text loss 0.7607 | 69600/ 8196 batches
[2025-05-14 03:53:35.896250]: text loss 0.7564 | 69800/ 8196 batches
[2025-05-14 03:55:14.058664]: text loss 0.7556 | 70000/ 8196 batches
[2025-05-14 03:56:49.968169]: text loss 0.7518 | 70200/ 8196 batches
[2025-05-14 03:58:25.959990]: text loss 0.7614 | 70400/ 8196 batches
[2025-05-14 04:00:01.810746]: text loss 0.7644 | 70600/ 8196 batches
[2025-05-14 04:01:39.292145]: text loss 0.7622 | 70800/ 8196 batches
[2025-05-14 04:03:18.132727]: text loss 0.7516 | 71000/ 8196 batches
[2025-05-14 04:04:56.426729]: text loss 0.7575 | 71200/ 8196 batches
[2025-05-14 04:06:35.571034]: text loss 0.7555 | 71400/ 8196 batches
[2025-05-14 04:08:13.013881]: text loss 0.7553 | 71600/ 8196 batches
[2025-05-14 04:09:48.842264]: text loss 0.7598 | 71800/ 8196 batches
[2025-05-14 04:11:24.682573]: text loss 0.7654 | 72000/ 8196 batches
[2025-05-14 04:13:00.362384]: text loss 0.7559 | 72200/ 8196 batches
[2025-05-14 04:14:36.034688]: text loss 0.7621 | 72400/ 8196 batches
[2025-05-14 04:16:12.578371]: text loss 0.7600 | 72600/ 8196 batches
[2025-05-14 04:17:50.801786]: text loss 0.7630 | 72800/ 8196 batches
[2025-05-14 04:19:27.587215]: text loss 0.7547 | 73000/ 8196 batches
[2025-05-14 04:21:03.519369]: text loss 0.7652 | 73200/ 8196 batches
[2025-05-14 04:22:39.634989]: text loss 0.7613 | 73400/ 8196 batches
[2025-05-14 04:24:15.700608]: text loss 0.7616 | 73600/ 8196 batches
[2025-05-14 04:25:34.327310]: text loss 0.7598 | 73764/ 8196 batches
[2025-05-14 04:25:34.327859]: validation
[2025-05-14 04:25:36.463854]: explanation loss 2.1267
[2025-05-14 04:25:40.336857]: rationale loss 1.2421
[2025-05-14 04:25:49.337356]: sequential loss 2.2538
[2025-05-14 04:26:47.006236]: top-N loss 1.2459
[2025-05-14 04:26:47.006322]: Endured 1 time(s)
[2025-05-14 04:26:47.006351]: epoch 10
[2025-05-14 04:27:04.266603]: text loss 0.7433 | 73800/ 8196 batches
[2025-05-14 04:28:39.895063]: text loss 0.7382 | 74000/ 8196 batches
[2025-05-14 04:30:15.885293]: text loss 0.7470 | 74200/ 8196 batches
[2025-05-14 04:31:51.783663]: text loss 0.7456 | 74400/ 8196 batches
[2025-05-14 04:33:27.590688]: text loss 0.7405 | 74600/ 8196 batches
[2025-05-14 04:35:03.239941]: text loss 0.7387 | 74800/ 8196 batches
[2025-05-14 04:36:38.897096]: text loss 0.7444 | 75000/ 8196 batches
[2025-05-14 04:38:16.419266]: text loss 0.7417 | 75200/ 8196 batches
[2025-05-14 04:39:54.284638]: text loss 0.7370 | 75400/ 8196 batches
[2025-05-14 04:41:29.842277]: text loss 0.7442 | 75600/ 8196 batches
[2025-05-14 04:43:05.466872]: text loss 0.7544 | 75800/ 8196 batches
[2025-05-14 04:44:41.090218]: text loss 0.7504 | 76000/ 8196 batches
[2025-05-14 04:46:16.754991]: text loss 0.7474 | 76200/ 8196 batches
[2025-05-14 04:47:55.094567]: text loss 0.7432 | 76400/ 8196 batches
[2025-05-14 04:49:33.355775]: text loss 0.7409 | 76600/ 8196 batches
[2025-05-14 04:51:11.547959]: text loss 0.7518 | 76800/ 8196 batches
[2025-05-14 04:52:49.260851]: text loss 0.7527 | 77000/ 8196 batches
[2025-05-14 04:54:24.852007]: text loss 0.7508 | 77200/ 8196 batches
[2025-05-14 04:56:02.219735]: text loss 0.7492 | 77400/ 8196 batches
[2025-05-14 04:57:40.357307]: text loss 0.7457 | 77600/ 8196 batches
[2025-05-14 04:59:18.439883]: text loss 0.7535 | 77800/ 8196 batches
[2025-05-14 05:00:56.382859]: text loss 0.7445 | 78000/ 8196 batches
[2025-05-14 05:02:31.860605]: text loss 0.7442 | 78200/ 8196 batches
[2025-05-14 05:04:07.632350]: text loss 0.7506 | 78400/ 8196 batches
[2025-05-14 05:05:43.287988]: text loss 0.7521 | 78600/ 8196 batches
[2025-05-14 05:07:20.335211]: text loss 0.7478 | 78800/ 8196 batches
[2025-05-14 05:08:57.956807]: text loss 0.7511 | 79000/ 8196 batches
[2025-05-14 05:10:34.801621]: text loss 0.7538 | 79200/ 8196 batches
[2025-05-14 05:12:10.586720]: text loss 0.7486 | 79400/ 8196 batches
[2025-05-14 05:13:46.359101]: text loss 0.7561 | 79600/ 8196 batches
[2025-05-14 05:15:22.157691]: text loss 0.7477 | 79800/ 8196 batches
[2025-05-14 05:16:57.842198]: text loss 0.7469 | 80000/ 8196 batches
[2025-05-14 05:18:33.476689]: text loss 0.7455 | 80200/ 8196 batches
[2025-05-14 05:20:09.150289]: text loss 0.7506 | 80400/ 8196 batches
[2025-05-14 05:21:44.762008]: text loss 0.7546 | 80600/ 8196 batches
[2025-05-14 05:23:22.052205]: text loss 0.7475 | 80800/ 8196 batches
[2025-05-14 05:24:57.834291]: text loss 0.7517 | 81000/ 8196 batches
[2025-05-14 05:26:36.049407]: text loss 0.7543 | 81200/ 8196 batches
[2025-05-14 05:28:13.300083]: text loss 0.7587 | 81400/ 8196 batches
[2025-05-14 05:29:48.925362]: text loss 0.7518 | 81600/ 8196 batches
[2025-05-14 05:31:24.343969]: text loss 0.7597 | 81800/ 8196 batches
[2025-05-14 05:32:41.895857]: text loss 0.7511 | 81960/ 8196 batches
[2025-05-14 05:32:41.896480]: validation
[2025-05-14 05:32:44.032572]: explanation loss 2.1330
[2025-05-14 05:32:47.881743]: rationale loss 1.2418
[2025-05-14 05:32:56.842457]: sequential loss 2.2706
[2025-05-14 05:33:54.382154]: top-N loss 1.2416
[2025-05-14 05:33:54.382239]: Endured 2 time(s)
[2025-05-14 05:33:54.382257]: epoch 11
[2025-05-14 05:34:13.509705]: text loss 0.7283 | 82000/ 8196 batches
[2025-05-14 05:35:49.218991]: text loss 0.7296 | 82200/ 8196 batches
[2025-05-14 05:37:27.184220]: text loss 0.7335 | 82400/ 8196 batches
[2025-05-14 05:39:05.124068]: text loss 0.7346 | 82600/ 8196 batches
[2025-05-14 05:40:43.205545]: text loss 0.7335 | 82800/ 8196 batches
[2025-05-14 05:42:21.137591]: text loss 0.7355 | 83000/ 8196 batches
[2025-05-14 05:43:58.824010]: text loss 0.7355 | 83200/ 8196 batches
[2025-05-14 05:45:36.807348]: text loss 0.7341 | 83400/ 8196 batches
[2025-05-14 05:47:14.839093]: text loss 0.7383 | 83600/ 8196 batches
[2025-05-14 05:48:52.816029]: text loss 0.7377 | 83800/ 8196 batches
[2025-05-14 05:50:28.289320]: text loss 0.7505 | 84000/ 8196 batches
[2025-05-14 05:52:04.836447]: text loss 0.7334 | 84200/ 8196 batches
[2025-05-14 05:53:40.621920]: text loss 0.7299 | 84400/ 8196 batches
[2025-05-14 05:55:16.025458]: text loss 0.7348 | 84600/ 8196 batches
[2025-05-14 05:56:51.613285]: text loss 0.7444 | 84800/ 8196 batches
[2025-05-14 05:58:27.033584]: text loss 0.7411 | 85000/ 8196 batches
[2025-05-14 06:00:02.511458]: text loss 0.7432 | 85200/ 8196 batches
[2025-05-14 06:01:37.970820]: text loss 0.7409 | 85400/ 8196 batches
[2025-05-14 06:03:13.541219]: text loss 0.7305 | 85600/ 8196 batches
[2025-05-14 06:04:48.995918]: text loss 0.7418 | 85800/ 8196 batches
[2025-05-14 06:06:24.447169]: text loss 0.7385 | 86000/ 8196 batches
[2025-05-14 06:07:59.938790]: text loss 0.7392 | 86200/ 8196 batches
[2025-05-14 06:09:35.365300]: text loss 0.7353 | 86400/ 8196 batches
[2025-05-14 06:11:10.792828]: text loss 0.7388 | 86600/ 8196 batches
[2025-05-14 06:12:46.207973]: text loss 0.7423 | 86800/ 8196 batches
[2025-05-14 06:14:21.626366]: text loss 0.7437 | 87000/ 8196 batches
[2025-05-14 06:15:56.983121]: text loss 0.7408 | 87200/ 8196 batches
[2025-05-14 06:17:32.431902]: text loss 0.7481 | 87400/ 8196 batches
[2025-05-14 06:19:07.971962]: text loss 0.7428 | 87600/ 8196 batches
[2025-05-14 06:20:43.650874]: text loss 0.7406 | 87800/ 8196 batches
[2025-05-14 06:22:19.044642]: text loss 0.7500 | 88000/ 8196 batches
[2025-05-14 06:23:54.474961]: text loss 0.7416 | 88200/ 8196 batches
[2025-05-14 06:25:29.896882]: text loss 0.7443 | 88400/ 8196 batches
[2025-05-14 06:27:06.528222]: text loss 0.7425 | 88600/ 8196 batches
[2025-05-14 06:28:41.931516]: text loss 0.7390 | 88800/ 8196 batches
[2025-05-14 06:30:17.363306]: text loss 0.7398 | 89000/ 8196 batches
[2025-05-14 06:31:52.929866]: text loss 0.7462 | 89200/ 8196 batches
[2025-05-14 06:33:28.551300]: text loss 0.7428 | 89400/ 8196 batches
[2025-05-14 06:35:04.048597]: text loss 0.7336 | 89600/ 8196 batches
[2025-05-14 06:36:39.485311]: text loss 0.7414 | 89800/ 8196 batches
[2025-05-14 06:38:14.857183]: text loss 0.7476 | 90000/ 8196 batches
[2025-05-14 06:39:29.220400]: text loss 0.7405 | 90156/ 8196 batches
[2025-05-14 06:39:29.220930]: validation
[2025-05-14 06:39:31.336295]: explanation loss 2.1362
[2025-05-14 06:39:35.179296]: rationale loss 1.2379
[2025-05-14 06:39:44.172068]: sequential loss 2.2586
[2025-05-14 06:40:41.672839]: top-N loss 1.2452
[2025-05-14 06:40:41.673036]: Endured 3 time(s)
[2025-05-14 06:40:41.673052]: epoch 12
[2025-05-14 06:41:02.690037]: text loss 0.7274 | 90200/ 8196 batches
[2025-05-14 06:42:38.000164]: text loss 0.7214 | 90400/ 8196 batches
[2025-05-14 06:44:13.821218]: text loss 0.7226 | 90600/ 8196 batches
[2025-05-14 06:45:49.166398]: text loss 0.7305 | 90800/ 8196 batches
[2025-05-14 06:47:24.562182]: text loss 0.7214 | 91000/ 8196 batches
[2025-05-14 06:48:59.874599]: text loss 0.7269 | 91200/ 8196 batches
[2025-05-14 06:50:35.255794]: text loss 0.7250 | 91400/ 8196 batches
[2025-05-14 06:52:10.673652]: text loss 0.7282 | 91600/ 8196 batches
[2025-05-14 06:53:46.139023]: text loss 0.7220 | 91800/ 8196 batches
[2025-05-14 06:55:21.652684]: text loss 0.7253 | 92000/ 8196 batches
[2025-05-14 06:56:57.149479]: text loss 0.7288 | 92200/ 8196 batches
[2025-05-14 06:58:32.581186]: text loss 0.7333 | 92400/ 8196 batches
[2025-05-14 07:00:07.981937]: text loss 0.7321 | 92600/ 8196 batches
[2025-05-14 07:01:43.370352]: text loss 0.7259 | 92800/ 8196 batches
[2025-05-14 07:03:18.749956]: text loss 0.7405 | 93000/ 8196 batches
[2025-05-14 07:04:54.140922]: text loss 0.7287 | 93200/ 8196 batches
[2025-05-14 07:06:29.464078]: text loss 0.7300 | 93400/ 8196 batches
[2025-05-14 07:08:05.942850]: text loss 0.7354 | 93600/ 8196 batches
[2025-05-14 07:09:42.881202]: text loss 0.7309 | 93800/ 8196 batches
[2025-05-14 07:11:20.722410]: text loss 0.7348 | 94000/ 8196 batches
[2025-05-14 07:12:58.603422]: text loss 0.7333 | 94200/ 8196 batches
[2025-05-14 07:14:36.323240]: text loss 0.7321 | 94400/ 8196 batches
[2025-05-14 07:16:14.230129]: text loss 0.7305 | 94600/ 8196 batches
[2025-05-14 07:17:52.242407]: text loss 0.7313 | 94800/ 8196 batches
[2025-05-14 07:19:30.196730]: text loss 0.7250 | 95000/ 8196 batches
[2025-05-14 07:21:08.182383]: text loss 0.7321 | 95200/ 8196 batches
[2025-05-14 07:22:46.232104]: text loss 0.7267 | 95400/ 8196 batches
[2025-05-14 07:24:22.217136]: text loss 0.7349 | 95600/ 8196 batches
[2025-05-14 07:25:57.546968]: text loss 0.7294 | 95800/ 8196 batches
[2025-05-14 07:27:32.907783]: text loss 0.7311 | 96000/ 8196 batches
[2025-05-14 07:29:08.246457]: text loss 0.7341 | 96200/ 8196 batches
[2025-05-14 07:30:43.603358]: text loss 0.7355 | 96400/ 8196 batches
[2025-05-14 07:32:18.944289]: text loss 0.7256 | 96600/ 8196 batches
[2025-05-14 07:33:54.325436]: text loss 0.7299 | 96800/ 8196 batches
[2025-05-14 07:35:29.682383]: text loss 0.7335 | 97000/ 8196 batches
[2025-05-14 07:37:05.017386]: text loss 0.7353 | 97200/ 8196 batches
[2025-05-14 07:38:40.334115]: text loss 0.7369 | 97400/ 8196 batches
[2025-05-14 07:40:16.436885]: text loss 0.7376 | 97600/ 8196 batches
[2025-05-14 07:41:52.245212]: text loss 0.7320 | 97800/ 8196 batches
[2025-05-14 07:43:28.057620]: text loss 0.7363 | 98000/ 8196 batches
[2025-05-14 07:45:03.882703]: text loss 0.7414 | 98200/ 8196 batches
[2025-05-14 07:46:16.672395]: text loss 0.7244 | 98352/ 8196 batches
[2025-05-14 07:46:16.672905]: validation
[2025-05-14 07:46:18.791745]: explanation loss 2.1442
[2025-05-14 07:46:22.652401]: rationale loss 1.2380
[2025-05-14 07:46:31.606116]: sequential loss 2.3091
[2025-05-14 07:47:29.213589]: top-N loss 1.2632
[2025-05-14 07:47:29.213678]: Endured 4 time(s)
[2025-05-14 07:47:29.213692]: epoch 13
[2025-05-14 07:47:52.138509]: text loss 0.7210 | 98400/ 8196 batches
[2025-05-14 07:49:29.905497]: text loss 0.7133 | 98600/ 8196 batches
[2025-05-14 07:51:07.199309]: text loss 0.7228 | 98800/ 8196 batches
[2025-05-14 07:52:42.507232]: text loss 0.7118 | 99000/ 8196 batches
[2025-05-14 07:54:17.801672]: text loss 0.7234 | 99200/ 8196 batches
[2025-05-14 07:55:53.101897]: text loss 0.7149 | 99400/ 8196 batches
[2025-05-14 07:57:28.453424]: text loss 0.7115 | 99600/ 8196 batches
[2025-05-14 07:59:03.723159]: text loss 0.7169 | 99800/ 8196 batches
[2025-05-14 08:00:39.584815]: text loss 0.7170 | 100000/ 8196 batches
[2025-05-14 08:02:17.348379]: text loss 0.7308 | 100200/ 8196 batches
[2025-05-14 08:03:54.782119]: text loss 0.7163 | 100400/ 8196 batches
[2025-05-14 08:05:30.042051]: text loss 0.7203 | 100600/ 8196 batches
[2025-05-14 08:07:07.520842]: text loss 0.7200 | 100800/ 8196 batches
[2025-05-14 08:08:45.411499]: text loss 0.7249 | 101000/ 8196 batches
[2025-05-14 08:10:23.391051]: text loss 0.7242 | 101200/ 8196 batches
[2025-05-14 08:12:01.429382]: text loss 0.7182 | 101400/ 8196 batches
[2025-05-14 08:13:39.471664]: text loss 0.7193 | 101600/ 8196 batches
[2025-05-14 08:15:17.508064]: text loss 0.7245 | 101800/ 8196 batches
[2025-05-14 08:16:52.964417]: text loss 0.7229 | 102000/ 8196 batches
[2025-05-14 08:18:30.581945]: text loss 0.7222 | 102200/ 8196 batches
[2025-05-14 08:20:08.451270]: text loss 0.7203 | 102400/ 8196 batches
[2025-05-14 08:21:46.169108]: text loss 0.7159 | 102600/ 8196 batches
[2025-05-14 08:23:24.012757]: text loss 0.7252 | 102800/ 8196 batches
[2025-05-14 08:25:01.926228]: text loss 0.7205 | 103000/ 8196 batches
[2025-05-14 08:26:39.059873]: text loss 0.7330 | 103200/ 8196 batches
[2025-05-14 08:28:14.403415]: text loss 0.7150 | 103400/ 8196 batches
[2025-05-14 08:29:49.772155]: text loss 0.7235 | 103600/ 8196 batches
[2025-05-14 08:31:25.085936]: text loss 0.7263 | 103800/ 8196 batches
[2025-05-14 08:33:00.463320]: text loss 0.7309 | 104000/ 8196 batches
[2025-05-14 08:34:35.838599]: text loss 0.7120 | 104200/ 8196 batches
[2025-05-14 08:36:11.265301]: text loss 0.7206 | 104400/ 8196 batches
[2025-05-14 08:37:46.754338]: text loss 0.7142 | 104600/ 8196 batches
[2025-05-14 08:39:22.251048]: text loss 0.7273 | 104800/ 8196 batches
[2025-05-14 08:40:57.639569]: text loss 0.7291 | 105000/ 8196 batches
[2025-05-14 08:42:33.074554]: text loss 0.7156 | 105200/ 8196 batches
[2025-05-14 08:44:08.481211]: text loss 0.7168 | 105400/ 8196 batches
[2025-05-14 08:45:43.841920]: text loss 0.7221 | 105600/ 8196 batches
[2025-05-14 08:47:21.338140]: text loss 0.7208 | 105800/ 8196 batches
[2025-05-14 08:48:59.237663]: text loss 0.7243 | 106000/ 8196 batches
[2025-05-14 08:50:37.204686]: text loss 0.7251 | 106200/ 8196 batches
[2025-05-14 08:52:14.604413]: text loss 0.7236 | 106400/ 8196 batches
[2025-05-14 08:53:25.311048]: text loss 0.7277 | 106548/ 8196 batches
[2025-05-14 08:53:25.311576]: validation
[2025-05-14 08:53:27.452276]: explanation loss 2.1404
[2025-05-14 08:53:31.311736]: rationale loss 1.2299
[2025-05-14 08:53:40.427708]: sequential loss 2.3015
[2025-05-14 08:54:37.928004]: top-N loss 1.2831
[2025-05-14 08:54:37.928092]: Endured 5 time(s)
[2025-05-14 08:54:37.928105]: Cannot endure it anymore | Exiting from early stop
