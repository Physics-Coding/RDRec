nohup: ignoring input
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/zhongyikun/anaconda3/envs/RDRec/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Some weights of Solomon were not initialized from the model checkpoint at t5-small and are newly initialized: ['conv1d.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------------------------------ARGUMENTS----------------------------------------
data_dir                                 ./data/toys/
model_version                            0
task_num                                 5
prompt_num                               3
lr                                       0.0005
ratio                                    1:1:1:3
epochs                                   100
batch_size                               64
cuda                                     True
log_interval                             200
checkpoint                               ./checkpoint_0520_max/toys_1113/
endure_times                             5
exp_len                                  20
negative_num                             99
----------------------------------------ARGUMENTS----------------------------------------
[2025-05-20 16:36:27.120588]: Loading data
[2025-05-20 16:36:36.987375]: Start training
[2025-05-20 16:36:36.987466]: epoch 1
[2025-05-20 16:38:15.059801]: text loss 1.2557 |   200/ 8196 batches
[2025-05-20 16:39:52.762353]: text loss 0.9435 |   400/ 8196 batches
[2025-05-20 16:41:29.980336]: text loss 0.8994 |   600/ 8196 batches
[2025-05-20 16:43:07.644963]: text loss 0.8905 |   800/ 8196 batches
[2025-05-20 16:44:45.384525]: text loss 0.8694 |  1000/ 8196 batches
[2025-05-20 16:46:23.226498]: text loss 0.8777 |  1200/ 8196 batches
[2025-05-20 16:48:00.906853]: text loss 0.8724 |  1400/ 8196 batches
[2025-05-20 16:49:38.442842]: text loss 0.8593 |  1600/ 8196 batches
[2025-05-20 16:51:15.958563]: text loss 0.8450 |  1800/ 8196 batches
[2025-05-20 16:52:53.782876]: text loss 0.8346 |  2000/ 8196 batches
[2025-05-20 16:54:31.387334]: text loss 0.8484 |  2200/ 8196 batches
[2025-05-20 16:56:09.163851]: text loss 0.8511 |  2400/ 8196 batches
[2025-05-20 16:57:46.450911]: text loss 0.8429 |  2600/ 8196 batches
[2025-05-20 16:59:24.081222]: text loss 0.8430 |  2800/ 8196 batches
[2025-05-20 17:01:01.947328]: text loss 0.8464 |  3000/ 8196 batches
[2025-05-20 17:02:39.886568]: text loss 0.8613 |  3200/ 8196 batches
[2025-05-20 17:04:17.403646]: text loss 0.8376 |  3400/ 8196 batches
[2025-05-20 17:05:55.309480]: text loss 0.8359 |  3600/ 8196 batches
[2025-05-20 17:07:33.121582]: text loss 0.8328 |  3800/ 8196 batches
[2025-05-20 17:09:10.964774]: text loss 0.8503 |  4000/ 8196 batches
[2025-05-20 17:10:48.743529]: text loss 0.8386 |  4200/ 8196 batches
[2025-05-20 17:12:26.521191]: text loss 0.8278 |  4400/ 8196 batches
[2025-05-20 17:14:04.148481]: text loss 0.8380 |  4600/ 8196 batches
[2025-05-20 17:15:41.861606]: text loss 0.8378 |  4800/ 8196 batches
[2025-05-20 17:17:19.470529]: text loss 0.8648 |  5000/ 8196 batches
[2025-05-20 17:18:56.908739]: text loss 0.8574 |  5200/ 8196 batches
[2025-05-20 17:20:34.380004]: text loss 0.8347 |  5400/ 8196 batches
[2025-05-20 17:22:12.008592]: text loss 0.8476 |  5600/ 8196 batches
[2025-05-20 17:23:49.877838]: text loss 0.8426 |  5800/ 8196 batches
[2025-05-20 17:25:27.585198]: text loss 0.8310 |  6000/ 8196 batches
[2025-05-20 17:27:05.211018]: text loss 0.8365 |  6200/ 8196 batches
[2025-05-20 17:28:42.899102]: text loss 0.8561 |  6400/ 8196 batches
[2025-05-20 17:30:20.523950]: text loss 0.8468 |  6600/ 8196 batches
[2025-05-20 17:31:58.192006]: text loss 0.8601 |  6800/ 8196 batches
[2025-05-20 17:33:36.055152]: text loss 0.8294 |  7000/ 8196 batches
[2025-05-20 17:35:14.002516]: text loss 0.8539 |  7200/ 8196 batches
[2025-05-20 17:36:51.565136]: text loss 0.8499 |  7400/ 8196 batches
[2025-05-20 17:38:29.242489]: text loss 0.8447 |  7600/ 8196 batches
[2025-05-20 17:40:06.919056]: text loss 0.8535 |  7800/ 8196 batches
[2025-05-20 17:41:44.820773]: text loss 0.8548 |  8000/ 8196 batches
[2025-05-20 17:43:20.643170]: text loss 0.8547 |  8196/ 8196 batches
[2025-05-20 17:43:20.643920]: validation
[2025-05-20 17:43:22.819873]: explanation loss 2.2301
[2025-05-20 17:43:26.755630]: rationale loss 1.1202
[2025-05-20 17:43:35.996551]: sequential loss 2.4259
[2025-05-20 17:44:35.663158]: top-N loss 1.4556
[2025-05-20 17:44:36.104598]: epoch 2
[2025-05-20 17:44:38.106141]: text loss 0.8221 |  8200/ 8196 batches
[2025-05-20 17:46:15.907082]: text loss 0.8076 |  8400/ 8196 batches
[2025-05-20 17:47:53.727313]: text loss 0.7992 |  8600/ 8196 batches
[2025-05-20 17:49:31.334613]: text loss 0.8043 |  8800/ 8196 batches
[2025-05-20 17:51:09.023809]: text loss 0.8005 |  9000/ 8196 batches
[2025-05-20 17:52:46.744003]: text loss 0.8047 |  9200/ 8196 batches
[2025-05-20 17:54:24.604766]: text loss 0.8052 |  9400/ 8196 batches
[2025-05-20 17:56:02.174901]: text loss 0.8007 |  9600/ 8196 batches
[2025-05-20 17:57:39.711736]: text loss 0.7980 |  9800/ 8196 batches
[2025-05-20 17:59:17.300598]: text loss 0.8104 | 10000/ 8196 batches
[2025-05-20 18:00:54.955296]: text loss 0.8022 | 10200/ 8196 batches
[2025-05-20 18:02:32.217901]: text loss 0.7941 | 10400/ 8196 batches
[2025-05-20 18:04:09.899472]: text loss 0.7891 | 10600/ 8196 batches
[2025-05-20 18:05:47.404174]: text loss 0.7978 | 10800/ 8196 batches
[2025-05-20 18:07:25.066891]: text loss 0.8069 | 11000/ 8196 batches
[2025-05-20 18:09:02.677628]: text loss 0.7996 | 11200/ 8196 batches
[2025-05-20 18:10:40.207376]: text loss 0.7953 | 11400/ 8196 batches
[2025-05-20 18:12:17.590532]: text loss 0.7935 | 11600/ 8196 batches
[2025-05-20 18:13:55.397014]: text loss 0.7913 | 11800/ 8196 batches
[2025-05-20 18:15:33.308701]: text loss 0.7943 | 12000/ 8196 batches
[2025-05-20 18:17:11.167219]: text loss 0.7936 | 12200/ 8196 batches
[2025-05-20 18:18:49.251589]: text loss 0.7889 | 12400/ 8196 batches
[2025-05-20 18:20:27.098518]: text loss 0.7848 | 12600/ 8196 batches
[2025-05-20 18:22:04.627342]: text loss 0.8001 | 12800/ 8196 batches
[2025-05-20 18:23:41.825172]: text loss 0.7955 | 13000/ 8196 batches
[2025-05-20 18:25:19.663963]: text loss 0.7882 | 13200/ 8196 batches
[2025-05-20 18:26:57.458625]: text loss 0.7846 | 13400/ 8196 batches
[2025-05-20 18:28:35.016445]: text loss 0.7900 | 13600/ 8196 batches
[2025-05-20 18:30:13.022685]: text loss 0.8056 | 13800/ 8196 batches
[2025-05-20 18:31:50.519244]: text loss 0.7825 | 14000/ 8196 batches
[2025-05-20 18:33:28.010453]: text loss 0.8013 | 14200/ 8196 batches
[2025-05-20 18:35:05.635710]: text loss 0.7983 | 14400/ 8196 batches
[2025-05-20 18:36:43.203109]: text loss 0.7990 | 14600/ 8196 batches
[2025-05-20 18:38:20.780016]: text loss 0.7854 | 14800/ 8196 batches
[2025-05-20 18:39:58.393812]: text loss 0.7863 | 15000/ 8196 batches
[2025-05-20 18:41:35.968315]: text loss 0.8020 | 15200/ 8196 batches
[2025-05-20 18:43:13.355845]: text loss 0.7798 | 15400/ 8196 batches
[2025-05-20 18:44:51.086364]: text loss 0.7944 | 15600/ 8196 batches
[2025-05-20 18:46:28.709408]: text loss 0.7797 | 15800/ 8196 batches
[2025-05-20 18:48:06.400527]: text loss 0.7730 | 16000/ 8196 batches
[2025-05-20 18:49:44.304520]: text loss 0.7835 | 16200/ 8196 batches
[2025-05-20 18:51:17.897167]: text loss 0.7807 | 16392/ 8196 batches
[2025-05-20 18:51:17.898281]: validation
[2025-05-20 18:51:20.090552]: explanation loss 2.1692
[2025-05-20 18:51:24.020578]: rationale loss 1.0733
[2025-05-20 18:51:33.212758]: sequential loss 2.3821
[2025-05-20 18:52:32.825872]: top-N loss 1.3929
[2025-05-20 18:52:33.284219]: epoch 3
[2025-05-20 18:52:37.217029]: text loss 0.7998 | 16400/ 8196 batches
[2025-05-20 18:54:14.460112]: text loss 0.7660 | 16600/ 8196 batches
[2025-05-20 18:55:51.901103]: text loss 0.7674 | 16800/ 8196 batches
[2025-05-20 18:57:29.625338]: text loss 0.7655 | 17000/ 8196 batches
[2025-05-20 18:59:07.022370]: text loss 0.7698 | 17200/ 8196 batches
[2025-05-20 19:00:44.554847]: text loss 0.7804 | 17400/ 8196 batches
[2025-05-20 19:02:21.864077]: text loss 0.7756 | 17600/ 8196 batches
[2025-05-20 19:03:59.391009]: text loss 0.7814 | 17800/ 8196 batches
[2025-05-20 19:05:37.114779]: text loss 0.7761 | 18000/ 8196 batches
[2025-05-20 19:07:14.724678]: text loss 0.7722 | 18200/ 8196 batches
[2025-05-20 19:08:51.842442]: text loss 0.7824 | 18400/ 8196 batches
[2025-05-20 19:10:29.445092]: text loss 0.7729 | 18600/ 8196 batches
[2025-05-20 19:12:06.690885]: text loss 0.7805 | 18800/ 8196 batches
[2025-05-20 19:13:44.355748]: text loss 0.7677 | 19000/ 8196 batches
[2025-05-20 19:15:22.028856]: text loss 0.7692 | 19200/ 8196 batches
[2025-05-20 19:16:59.391512]: text loss 0.7696 | 19400/ 8196 batches
[2025-05-20 19:18:37.178849]: text loss 0.7631 | 19600/ 8196 batches
[2025-05-20 19:20:14.754576]: text loss 0.7626 | 19800/ 8196 batches
[2025-05-20 19:21:52.406555]: text loss 0.7665 | 20000/ 8196 batches
[2025-05-20 19:23:29.935924]: text loss 0.7705 | 20200/ 8196 batches
[2025-05-20 19:25:07.486989]: text loss 0.7483 | 20400/ 8196 batches
[2025-05-20 19:26:45.253289]: text loss 0.7701 | 20600/ 8196 batches
[2025-05-20 19:28:22.638367]: text loss 0.7715 | 20800/ 8196 batches
[2025-05-20 19:30:00.370210]: text loss 0.7668 | 21000/ 8196 batches
[2025-05-20 19:31:37.967230]: text loss 0.7683 | 21200/ 8196 batches
[2025-05-20 19:33:15.794095]: text loss 0.7690 | 21400/ 8196 batches
[2025-05-20 19:34:53.254982]: text loss 0.7744 | 21600/ 8196 batches
[2025-05-20 19:36:31.217117]: text loss 0.7642 | 21800/ 8196 batches
[2025-05-20 19:38:09.039753]: text loss 0.7651 | 22000/ 8196 batches
[2025-05-20 19:39:46.969901]: text loss 0.7740 | 22200/ 8196 batches
[2025-05-20 19:41:24.336647]: text loss 0.7702 | 22400/ 8196 batches
[2025-05-20 19:43:01.730216]: text loss 0.7609 | 22600/ 8196 batches
[2025-05-20 19:44:39.447346]: text loss 0.7565 | 22800/ 8196 batches
[2025-05-20 19:46:16.694432]: text loss 0.7704 | 23000/ 8196 batches
[2025-05-20 19:47:54.344084]: text loss 0.7698 | 23200/ 8196 batches
[2025-05-20 19:49:32.067753]: text loss 0.7689 | 23400/ 8196 batches
[2025-05-20 19:51:09.511953]: text loss 0.7663 | 23600/ 8196 batches
[2025-05-20 19:52:47.208640]: text loss 0.7639 | 23800/ 8196 batches
[2025-05-20 19:54:24.884179]: text loss 0.7588 | 24000/ 8196 batches
[2025-05-20 19:56:02.747237]: text loss 0.7641 | 24200/ 8196 batches
[2025-05-20 19:57:40.296187]: text loss 0.7540 | 24400/ 8196 batches
[2025-05-20 19:59:12.078756]: text loss 0.7643 | 24588/ 8196 batches
[2025-05-20 19:59:12.079550]: validation
[2025-05-20 19:59:14.255060]: explanation loss 2.1496
[2025-05-20 19:59:18.177582]: rationale loss 1.0567
[2025-05-20 19:59:27.421171]: sequential loss 2.3560
[2025-05-20 20:00:26.864454]: top-N loss 1.3226
[2025-05-20 20:00:27.325531]: epoch 4
[2025-05-20 20:00:33.229108]: text loss 0.7661 | 24600/ 8196 batches
[2025-05-20 20:02:10.867982]: text loss 0.7509 | 24800/ 8196 batches
[2025-05-20 20:03:48.438375]: text loss 0.7479 | 25000/ 8196 batches
[2025-05-20 20:05:26.077778]: text loss 0.7505 | 25200/ 8196 batches
[2025-05-20 20:07:03.542028]: text loss 0.7524 | 25400/ 8196 batches
[2025-05-20 20:08:41.108988]: text loss 0.7472 | 25600/ 8196 batches
[2025-05-20 20:10:18.665219]: text loss 0.7428 | 25800/ 8196 batches
[2025-05-20 20:11:56.366478]: text loss 0.7524 | 26000/ 8196 batches
[2025-05-20 20:13:33.898458]: text loss 0.7486 | 26200/ 8196 batches
[2025-05-20 20:15:11.322122]: text loss 0.7515 | 26400/ 8196 batches
[2025-05-20 20:16:49.145776]: text loss 0.7540 | 26600/ 8196 batches
[2025-05-20 20:18:26.812645]: text loss 0.7555 | 26800/ 8196 batches
[2025-05-20 20:20:04.117268]: text loss 0.7507 | 27000/ 8196 batches
[2025-05-20 20:21:41.998926]: text loss 0.7478 | 27200/ 8196 batches
[2025-05-20 20:23:19.381640]: text loss 0.7466 | 27400/ 8196 batches
[2025-05-20 20:24:56.755143]: text loss 0.7428 | 27600/ 8196 batches
[2025-05-20 20:26:33.856172]: text loss 0.7473 | 27800/ 8196 batches
[2025-05-20 20:28:11.501296]: text loss 0.7534 | 28000/ 8196 batches
[2025-05-20 20:29:48.924251]: text loss 0.7471 | 28200/ 8196 batches
[2025-05-20 20:31:26.293415]: text loss 0.7544 | 28400/ 8196 batches
[2025-05-20 20:33:03.748408]: text loss 0.7500 | 28600/ 8196 batches
[2025-05-20 20:34:42.038563]: text loss 0.7468 | 28800/ 8196 batches
[2025-05-20 20:36:19.682365]: text loss 0.7510 | 29000/ 8196 batches
[2025-05-20 20:37:57.107565]: text loss 0.7473 | 29200/ 8196 batches
[2025-05-20 20:39:34.435114]: text loss 0.7440 | 29400/ 8196 batches
[2025-05-20 20:41:12.102400]: text loss 0.7492 | 29600/ 8196 batches
[2025-05-20 20:42:49.671663]: text loss 0.7417 | 29800/ 8196 batches
[2025-05-20 20:44:27.054582]: text loss 0.7508 | 30000/ 8196 batches
[2025-05-20 20:46:04.510595]: text loss 0.7436 | 30200/ 8196 batches
[2025-05-20 20:47:41.764662]: text loss 0.7471 | 30400/ 8196 batches
[2025-05-20 20:49:19.051322]: text loss 0.7659 | 30600/ 8196 batches
[2025-05-20 20:50:56.797113]: text loss 0.7412 | 30800/ 8196 batches
[2025-05-20 20:52:34.969243]: text loss 0.7532 | 31000/ 8196 batches
[2025-05-20 20:54:12.967180]: text loss 0.7514 | 31200/ 8196 batches
[2025-05-20 20:55:50.980836]: text loss 0.7500 | 31400/ 8196 batches
[2025-05-20 20:57:28.930995]: text loss 0.7408 | 31600/ 8196 batches
[2025-05-20 20:59:06.966126]: text loss 0.7488 | 31800/ 8196 batches
[2025-05-20 21:00:44.213710]: text loss 0.7519 | 32000/ 8196 batches
[2025-05-20 21:02:22.151018]: text loss 0.7511 | 32200/ 8196 batches
[2025-05-20 21:04:00.351798]: text loss 0.7436 | 32400/ 8196 batches
[2025-05-20 21:05:38.187631]: text loss 0.7510 | 32600/ 8196 batches
[2025-05-20 21:07:08.447026]: text loss 0.7550 | 32784/ 8196 batches
[2025-05-20 21:07:08.447933]: validation
[2025-05-20 21:07:10.696244]: explanation loss 2.1384
[2025-05-20 21:07:14.632401]: rationale loss 1.0442
[2025-05-20 21:07:23.854726]: sequential loss 2.3252
[2025-05-20 21:08:23.218153]: top-N loss 1.2872
[2025-05-20 21:08:23.671257]: epoch 5
[2025-05-20 21:08:31.557603]: text loss 0.7337 | 32800/ 8196 batches
[2025-05-20 21:10:08.703335]: text loss 0.7319 | 33000/ 8196 batches
[2025-05-20 21:11:47.072023]: text loss 0.7324 | 33200/ 8196 batches
[2025-05-20 21:13:25.068428]: text loss 0.7354 | 33400/ 8196 batches
[2025-05-20 21:15:02.547354]: text loss 0.7267 | 33600/ 8196 batches
[2025-05-20 21:16:40.241684]: text loss 0.7275 | 33800/ 8196 batches
[2025-05-20 21:18:18.656196]: text loss 0.7367 | 34000/ 8196 batches
[2025-05-20 21:19:57.168974]: text loss 0.7377 | 34200/ 8196 batches
[2025-05-20 21:21:35.936347]: text loss 0.7316 | 34400/ 8196 batches
[2025-05-20 21:23:14.579745]: text loss 0.7403 | 34600/ 8196 batches
[2025-05-20 21:24:53.029364]: text loss 0.7397 | 34800/ 8196 batches
[2025-05-20 21:26:32.116037]: text loss 0.7413 | 35000/ 8196 batches
[2025-05-20 21:28:10.367944]: text loss 0.7313 | 35200/ 8196 batches
[2025-05-20 21:29:48.060344]: text loss 0.7340 | 35400/ 8196 batches
[2025-05-20 21:31:26.350798]: text loss 0.7306 | 35600/ 8196 batches
[2025-05-20 21:33:04.231767]: text loss 0.7408 | 35800/ 8196 batches
[2025-05-20 21:34:42.248410]: text loss 0.7291 | 36000/ 8196 batches
[2025-05-20 21:36:21.067580]: text loss 0.7392 | 36200/ 8196 batches
[2025-05-20 21:37:58.191004]: text loss 0.7339 | 36400/ 8196 batches
[2025-05-20 21:39:37.923188]: text loss 0.7379 | 36600/ 8196 batches
[2025-05-20 21:41:17.059219]: text loss 0.7286 | 36800/ 8196 batches
[2025-05-20 21:42:55.515698]: text loss 0.7279 | 37000/ 8196 batches
[2025-05-20 21:44:34.619365]: text loss 0.7369 | 37200/ 8196 batches
[2025-05-20 21:46:14.119977]: text loss 0.7361 | 37400/ 8196 batches
[2025-05-20 21:47:52.946315]: text loss 0.7277 | 37600/ 8196 batches
[2025-05-20 21:49:32.124571]: text loss 0.7404 | 37800/ 8196 batches
[2025-05-20 21:51:11.239711]: text loss 0.7350 | 38000/ 8196 batches
[2025-05-20 21:52:50.513662]: text loss 0.7398 | 38200/ 8196 batches
[2025-05-20 21:54:30.114054]: text loss 0.7430 | 38400/ 8196 batches
[2025-05-20 21:56:08.863916]: text loss 0.7338 | 38600/ 8196 batches
[2025-05-20 21:57:47.651762]: text loss 0.7310 | 38800/ 8196 batches
[2025-05-20 21:59:26.697311]: text loss 0.7392 | 39000/ 8196 batches
[2025-05-20 22:01:05.140909]: text loss 0.7402 | 39200/ 8196 batches
[2025-05-20 22:02:44.120570]: text loss 0.7356 | 39400/ 8196 batches
[2025-05-20 22:04:23.494500]: text loss 0.7382 | 39600/ 8196 batches
[2025-05-20 22:06:01.160726]: text loss 0.7399 | 39800/ 8196 batches
[2025-05-20 22:07:39.855243]: text loss 0.7351 | 40000/ 8196 batches
[2025-05-20 22:09:17.495711]: text loss 0.7423 | 40200/ 8196 batches
[2025-05-20 22:10:56.087464]: text loss 0.7309 | 40400/ 8196 batches
[2025-05-20 22:12:35.527801]: text loss 0.7282 | 40600/ 8196 batches
[2025-05-20 22:14:14.686537]: text loss 0.7350 | 40800/ 8196 batches
[2025-05-20 22:15:43.649716]: text loss 0.7309 | 40980/ 8196 batches
[2025-05-20 22:15:43.650459]: validation
[2025-05-20 22:15:45.813470]: explanation loss 2.1326
[2025-05-20 22:15:49.719348]: rationale loss 1.0482
[2025-05-20 22:15:58.809826]: sequential loss 2.3251
[2025-05-20 22:16:57.750566]: top-N loss 1.2723
[2025-05-20 22:16:58.168666]: epoch 6
[2025-05-20 22:17:08.042713]: text loss 0.7570 | 41000/ 8196 batches
[2025-05-20 22:18:46.096962]: text loss 0.7183 | 41200/ 8196 batches
[2025-05-20 22:20:24.061222]: text loss 0.7189 | 41400/ 8196 batches
[2025-05-20 22:22:01.976015]: text loss 0.7280 | 41600/ 8196 batches
[2025-05-20 22:23:40.030195]: text loss 0.7180 | 41800/ 8196 batches
[2025-05-20 22:25:19.737591]: text loss 0.7266 | 42000/ 8196 batches
[2025-05-20 22:26:57.634656]: text loss 0.7224 | 42200/ 8196 batches
[2025-05-20 22:28:35.731563]: text loss 0.7306 | 42400/ 8196 batches
[2025-05-20 22:30:12.567421]: text loss 0.7252 | 42600/ 8196 batches
[2025-05-20 22:31:49.491026]: text loss 0.7210 | 42800/ 8196 batches
[2025-05-20 22:33:26.626559]: text loss 0.7247 | 43000/ 8196 batches
[2025-05-20 22:35:04.858785]: text loss 0.7131 | 43200/ 8196 batches
[2025-05-20 22:36:42.589702]: text loss 0.7262 | 43400/ 8196 batches
[2025-05-20 22:38:19.917025]: text loss 0.7222 | 43600/ 8196 batches
[2025-05-20 22:39:58.091784]: text loss 0.7292 | 43800/ 8196 batches
[2025-05-20 22:41:35.324208]: text loss 0.7158 | 44000/ 8196 batches
[2025-05-20 22:43:12.210854]: text loss 0.7275 | 44200/ 8196 batches
[2025-05-20 22:44:49.132298]: text loss 0.7285 | 44400/ 8196 batches
[2025-05-20 22:46:26.630968]: text loss 0.7210 | 44600/ 8196 batches
[2025-05-20 22:48:04.077151]: text loss 0.7221 | 44800/ 8196 batches
[2025-05-20 22:49:41.435182]: text loss 0.7189 | 45000/ 8196 batches
[2025-05-20 22:51:20.096482]: text loss 0.7207 | 45200/ 8196 batches
[2025-05-20 22:52:57.820321]: text loss 0.7291 | 45400/ 8196 batches
[2025-05-20 22:54:35.140110]: text loss 0.7190 | 45600/ 8196 batches
[2025-05-20 22:56:14.119293]: text loss 0.7246 | 45800/ 8196 batches
[2025-05-20 22:57:51.543856]: text loss 0.7223 | 46000/ 8196 batches
[2025-05-20 22:59:29.824290]: text loss 0.7279 | 46200/ 8196 batches
[2025-05-20 23:01:08.622274]: text loss 0.7286 | 46400/ 8196 batches
[2025-05-20 23:02:47.138675]: text loss 0.7225 | 46600/ 8196 batches
[2025-05-20 23:04:25.923802]: text loss 0.7223 | 46800/ 8196 batches
[2025-05-20 23:06:02.744212]: text loss 0.7326 | 47000/ 8196 batches
[2025-05-20 23:07:40.994090]: text loss 0.7188 | 47200/ 8196 batches
[2025-05-20 23:09:18.407524]: text loss 0.7177 | 47400/ 8196 batches
[2025-05-20 23:10:57.326166]: text loss 0.7203 | 47600/ 8196 batches
[2025-05-20 23:12:35.162192]: text loss 0.7283 | 47800/ 8196 batches
[2025-05-20 23:14:12.294630]: text loss 0.7333 | 48000/ 8196 batches
[2025-05-20 23:15:49.862314]: text loss 0.7197 | 48200/ 8196 batches
[2025-05-20 23:17:26.575314]: text loss 0.7219 | 48400/ 8196 batches
[2025-05-20 23:19:03.786897]: text loss 0.7241 | 48600/ 8196 batches
[2025-05-20 23:20:40.945657]: text loss 0.7231 | 48800/ 8196 batches
[2025-05-20 23:22:19.378458]: text loss 0.7140 | 49000/ 8196 batches
[2025-05-20 23:23:45.287543]: text loss 0.7268 | 49176/ 8196 batches
[2025-05-20 23:23:45.288195]: validation
[2025-05-20 23:23:47.447122]: explanation loss 2.1308
[2025-05-20 23:23:51.350706]: rationale loss 1.0494
[2025-05-20 23:24:00.341721]: sequential loss 2.2712
[2025-05-20 23:24:58.936239]: top-N loss 1.2570
[2025-05-20 23:24:59.364800]: epoch 7
[2025-05-20 23:25:11.108052]: text loss 0.7260 | 49200/ 8196 batches
[2025-05-20 23:26:49.492559]: text loss 0.7198 | 49400/ 8196 batches
[2025-05-20 23:28:27.973784]: text loss 0.7168 | 49600/ 8196 batches
[2025-05-20 23:30:05.502924]: text loss 0.7133 | 49800/ 8196 batches
[2025-05-20 23:31:43.309487]: text loss 0.7024 | 50000/ 8196 batches
[2025-05-20 23:33:22.120159]: text loss 0.7088 | 50200/ 8196 batches
[2025-05-20 23:34:59.917567]: text loss 0.7170 | 50400/ 8196 batches
[2025-05-20 23:36:38.183460]: text loss 0.7168 | 50600/ 8196 batches
[2025-05-20 23:38:16.269957]: text loss 0.7165 | 50800/ 8196 batches
[2025-05-20 23:39:54.617147]: text loss 0.7038 | 51000/ 8196 batches
[2025-05-20 23:41:32.815291]: text loss 0.7132 | 51200/ 8196 batches
[2025-05-20 23:43:09.598511]: text loss 0.7083 | 51400/ 8196 batches
[2025-05-20 23:44:48.213131]: text loss 0.7134 | 51600/ 8196 batches
[2025-05-20 23:46:27.581794]: text loss 0.7066 | 51800/ 8196 batches
[2025-05-20 23:48:05.268625]: text loss 0.7160 | 52000/ 8196 batches
[2025-05-20 23:49:42.325606]: text loss 0.7063 | 52200/ 8196 batches
[2025-05-20 23:51:20.083534]: text loss 0.7176 | 52400/ 8196 batches
[2025-05-20 23:52:57.771795]: text loss 0.7205 | 52600/ 8196 batches
[2025-05-20 23:54:35.714859]: text loss 0.7001 | 52800/ 8196 batches
[2025-05-20 23:56:14.080703]: text loss 0.7097 | 53000/ 8196 batches
[2025-05-20 23:57:52.617058]: text loss 0.7070 | 53200/ 8196 batches
[2025-05-20 23:59:30.410648]: text loss 0.7081 | 53400/ 8196 batches
[2025-05-21 00:01:07.434332]: text loss 0.7168 | 53600/ 8196 batches
[2025-05-21 00:02:45.996335]: text loss 0.7158 | 53800/ 8196 batches
[2025-05-21 00:04:23.074694]: text loss 0.7059 | 54000/ 8196 batches
[2025-05-21 00:06:00.170812]: text loss 0.7188 | 54200/ 8196 batches
[2025-05-21 00:07:39.346364]: text loss 0.7096 | 54400/ 8196 batches
[2025-05-21 00:09:18.214334]: text loss 0.7199 | 54600/ 8196 batches
[2025-05-21 00:10:54.982292]: text loss 0.7198 | 54800/ 8196 batches
[2025-05-21 00:12:32.855892]: text loss 0.7066 | 55000/ 8196 batches
[2025-05-21 00:14:09.997838]: text loss 0.7179 | 55200/ 8196 batches
[2025-05-21 00:15:46.293074]: text loss 0.7099 | 55400/ 8196 batches
[2025-05-21 00:17:25.231138]: text loss 0.7078 | 55600/ 8196 batches
[2025-05-21 00:19:01.686223]: text loss 0.7194 | 55800/ 8196 batches
[2025-05-21 00:20:37.895529]: text loss 0.7148 | 56000/ 8196 batches
[2025-05-21 00:22:16.205236]: text loss 0.7215 | 56200/ 8196 batches
[2025-05-21 00:23:53.330871]: text loss 0.7103 | 56400/ 8196 batches
[2025-05-21 00:25:31.900598]: text loss 0.7205 | 56600/ 8196 batches
[2025-05-21 00:27:08.554784]: text loss 0.7177 | 56800/ 8196 batches
[2025-05-21 00:28:45.380822]: text loss 0.7095 | 57000/ 8196 batches
[2025-05-21 00:30:24.188305]: text loss 0.7179 | 57200/ 8196 batches
[2025-05-21 00:31:48.150087]: text loss 0.7190 | 57372/ 8196 batches
[2025-05-21 00:31:48.150693]: validation
[2025-05-21 00:31:50.307098]: explanation loss 2.1245
[2025-05-21 00:31:54.216478]: rationale loss 1.0379
[2025-05-21 00:32:03.200477]: sequential loss 2.3214
[2025-05-21 00:33:00.795197]: top-N loss 1.2421
[2025-05-21 00:33:00.795299]: Endured 1 time(s)
[2025-05-21 00:33:00.795333]: epoch 8
[2025-05-21 00:33:14.304581]: text loss 0.6951 | 57400/ 8196 batches
[2025-05-21 00:34:51.689225]: text loss 0.7021 | 57600/ 8196 batches
[2025-05-21 00:36:28.229912]: text loss 0.6959 | 57800/ 8196 batches
[2025-05-21 00:38:04.676660]: text loss 0.6992 | 58000/ 8196 batches
[2025-05-21 00:39:41.064221]: text loss 0.7008 | 58200/ 8196 batches
[2025-05-21 00:41:19.753978]: text loss 0.7037 | 58400/ 8196 batches
[2025-05-21 00:42:57.889958]: text loss 0.7008 | 58600/ 8196 batches
[2025-05-21 00:44:35.504653]: text loss 0.7027 | 58800/ 8196 batches
[2025-05-21 00:46:14.695957]: text loss 0.7031 | 59000/ 8196 batches
[2025-05-21 00:47:53.535568]: text loss 0.7013 | 59200/ 8196 batches
[2025-05-21 00:49:32.819731]: text loss 0.7196 | 59400/ 8196 batches
[2025-05-21 00:51:12.110466]: text loss 0.7021 | 59600/ 8196 batches
[2025-05-21 00:52:49.589554]: text loss 0.7026 | 59800/ 8196 batches
[2025-05-21 00:54:26.720841]: text loss 0.6983 | 60000/ 8196 batches
[2025-05-21 00:56:05.909757]: text loss 0.7009 | 60200/ 8196 batches
[2025-05-21 00:57:45.112085]: text loss 0.7000 | 60400/ 8196 batches
[2025-05-21 00:59:24.984253]: text loss 0.7061 | 60600/ 8196 batches
[2025-05-21 01:01:03.951986]: text loss 0.7006 | 60800/ 8196 batches
[2025-05-21 01:02:41.326673]: text loss 0.7022 | 61000/ 8196 batches
[2025-05-21 01:04:20.428738]: text loss 0.7065 | 61200/ 8196 batches
[2025-05-21 01:05:59.468224]: text loss 0.7049 | 61400/ 8196 batches
[2025-05-21 01:07:37.849520]: text loss 0.6989 | 61600/ 8196 batches
[2025-05-21 01:09:14.927363]: text loss 0.7109 | 61800/ 8196 batches
[2025-05-21 01:10:51.737719]: text loss 0.7083 | 62000/ 8196 batches
[2025-05-21 01:12:30.666185]: text loss 0.7019 | 62200/ 8196 batches
[2025-05-21 01:14:09.405615]: text loss 0.7074 | 62400/ 8196 batches
[2025-05-21 01:15:48.236028]: text loss 0.7020 | 62600/ 8196 batches
[2025-05-21 01:17:24.687481]: text loss 0.7077 | 62800/ 8196 batches
[2025-05-21 01:19:00.968818]: text loss 0.6984 | 63000/ 8196 batches
[2025-05-21 01:20:37.224804]: text loss 0.7027 | 63200/ 8196 batches
[2025-05-21 01:22:13.536473]: text loss 0.7031 | 63400/ 8196 batches
[2025-05-21 01:23:50.241111]: text loss 0.7101 | 63600/ 8196 batches
[2025-05-21 01:25:26.548535]: text loss 0.7006 | 63800/ 8196 batches
[2025-05-21 01:27:04.647057]: text loss 0.7058 | 64000/ 8196 batches
[2025-05-21 01:28:41.643427]: text loss 0.7082 | 64200/ 8196 batches
[2025-05-21 01:30:18.312889]: text loss 0.7103 | 64400/ 8196 batches
[2025-05-21 01:31:55.897488]: text loss 0.7038 | 64600/ 8196 batches
[2025-05-21 01:33:33.233154]: text loss 0.7011 | 64800/ 8196 batches
[2025-05-21 01:35:10.503235]: text loss 0.7063 | 65000/ 8196 batches
[2025-05-21 01:36:47.585381]: text loss 0.7042 | 65200/ 8196 batches
[2025-05-21 01:38:26.696028]: text loss 0.6999 | 65400/ 8196 batches
[2025-05-21 01:39:49.994334]: text loss 0.7059 | 65568/ 8196 batches
[2025-05-21 01:39:49.994982]: validation
[2025-05-21 01:39:52.174697]: explanation loss 2.1331
[2025-05-21 01:39:56.101203]: rationale loss 1.0326
[2025-05-21 01:40:05.098226]: sequential loss 2.2696
[2025-05-21 01:41:02.826319]: top-N loss 1.2386
[2025-05-21 01:41:03.241374]: epoch 9
[2025-05-21 01:41:18.725646]: text loss 0.7146 | 65600/ 8196 batches
[2025-05-21 01:42:57.905484]: text loss 0.6935 | 65800/ 8196 batches
[2025-05-21 01:44:35.492046]: text loss 0.6916 | 66000/ 8196 batches
[2025-05-21 01:46:13.234589]: text loss 0.6872 | 66200/ 8196 batches
[2025-05-21 01:47:52.404566]: text loss 0.6878 | 66400/ 8196 batches
[2025-05-21 01:49:30.797940]: text loss 0.6931 | 66600/ 8196 batches
[2025-05-21 01:51:09.897626]: text loss 0.6975 | 66800/ 8196 batches
[2025-05-21 01:52:49.006698]: text loss 0.6801 | 67000/ 8196 batches
[2025-05-21 01:54:28.119008]: text loss 0.6934 | 67200/ 8196 batches
[2025-05-21 01:56:07.218730]: text loss 0.6934 | 67400/ 8196 batches
[2025-05-21 01:57:46.337787]: text loss 0.6948 | 67600/ 8196 batches
[2025-05-21 01:59:23.538247]: text loss 0.6933 | 67800/ 8196 batches
[2025-05-21 02:01:00.581569]: text loss 0.6933 | 68000/ 8196 batches
[2025-05-21 02:02:38.231318]: text loss 0.6909 | 68200/ 8196 batches
[2025-05-21 02:04:16.025825]: text loss 0.6992 | 68400/ 8196 batches
[2025-05-21 02:05:54.276952]: text loss 0.6936 | 68600/ 8196 batches
[2025-05-21 02:07:34.415307]: text loss 0.6884 | 68800/ 8196 batches
[2025-05-21 02:09:12.775495]: text loss 0.6942 | 69000/ 8196 batches
[2025-05-21 02:10:49.716692]: text loss 0.6992 | 69200/ 8196 batches
[2025-05-21 02:12:27.053844]: text loss 0.6965 | 69400/ 8196 batches
[2025-05-21 02:14:04.143655]: text loss 0.6950 | 69600/ 8196 batches
[2025-05-21 02:15:43.213568]: text loss 0.6972 | 69800/ 8196 batches
[2025-05-21 02:17:21.306190]: text loss 0.6986 | 70000/ 8196 batches
[2025-05-21 02:18:58.660077]: text loss 0.6965 | 70200/ 8196 batches
[2025-05-21 02:20:37.698170]: text loss 0.6919 | 70400/ 8196 batches
[2025-05-21 02:22:16.282631]: text loss 0.6953 | 70600/ 8196 batches
[2025-05-21 02:23:54.023513]: text loss 0.6966 | 70800/ 8196 batches
[2025-05-21 02:25:31.972198]: text loss 0.6923 | 71000/ 8196 batches
[2025-05-21 02:27:09.675906]: text loss 0.7023 | 71200/ 8196 batches
[2025-05-21 02:28:46.983554]: text loss 0.6986 | 71400/ 8196 batches
[2025-05-21 02:30:23.883259]: text loss 0.6943 | 71600/ 8196 batches
[2025-05-21 02:32:00.770529]: text loss 0.6929 | 71800/ 8196 batches
[2025-05-21 02:33:39.028956]: text loss 0.6946 | 72000/ 8196 batches
[2025-05-21 02:35:17.205772]: text loss 0.7033 | 72200/ 8196 batches
[2025-05-21 02:36:55.460399]: text loss 0.6999 | 72400/ 8196 batches
[2025-05-21 02:38:32.854336]: text loss 0.6927 | 72600/ 8196 batches
[2025-05-21 02:40:10.877837]: text loss 0.6989 | 72800/ 8196 batches
[2025-05-21 02:41:49.899362]: text loss 0.7028 | 73000/ 8196 batches
[2025-05-21 02:43:28.857881]: text loss 0.6976 | 73200/ 8196 batches
[2025-05-21 02:45:05.941803]: text loss 0.6987 | 73400/ 8196 batches
[2025-05-21 02:46:42.834062]: text loss 0.6881 | 73600/ 8196 batches
[2025-05-21 02:48:02.292176]: text loss 0.7029 | 73764/ 8196 batches
[2025-05-21 02:48:02.292733]: validation
[2025-05-21 02:48:04.458147]: explanation loss 2.1302
[2025-05-21 02:48:08.389926]: rationale loss 1.0305
[2025-05-21 02:48:17.600065]: sequential loss 2.2727
[2025-05-21 02:49:15.378910]: top-N loss 1.2313
[2025-05-21 02:49:15.785771]: epoch 10
[2025-05-21 02:49:33.150981]: text loss 0.6874 | 73800/ 8196 batches
[2025-05-21 02:51:11.023347]: text loss 0.6805 | 74000/ 8196 batches
[2025-05-21 02:52:47.894049]: text loss 0.6848 | 74200/ 8196 batches
[2025-05-21 02:54:26.364001]: text loss 0.6784 | 74400/ 8196 batches
[2025-05-21 02:56:04.939421]: text loss 0.6809 | 74600/ 8196 batches
[2025-05-21 02:57:41.865202]: text loss 0.6799 | 74800/ 8196 batches
[2025-05-21 02:59:18.510518]: text loss 0.6842 | 75000/ 8196 batches
[2025-05-21 03:00:56.874488]: text loss 0.6869 | 75200/ 8196 batches
[2025-05-21 03:02:35.346632]: text loss 0.6858 | 75400/ 8196 batches
[2025-05-21 03:04:12.404018]: text loss 0.6876 | 75600/ 8196 batches
[2025-05-21 03:05:51.243026]: text loss 0.6854 | 75800/ 8196 batches
[2025-05-21 03:07:30.438485]: text loss 0.6881 | 76000/ 8196 batches
[2025-05-21 03:09:08.097743]: text loss 0.6791 | 76200/ 8196 batches
[2025-05-21 03:10:44.416640]: text loss 0.6850 | 76400/ 8196 batches
[2025-05-21 03:12:21.374764]: text loss 0.6839 | 76600/ 8196 batches
[2025-05-21 03:13:59.928673]: text loss 0.6877 | 76800/ 8196 batches
[2025-05-21 03:15:36.798909]: text loss 0.6900 | 77000/ 8196 batches
[2025-05-21 03:17:15.634904]: text loss 0.6953 | 77200/ 8196 batches
[2025-05-21 03:18:54.200925]: text loss 0.6961 | 77400/ 8196 batches
[2025-05-21 03:20:31.205087]: text loss 0.6919 | 77600/ 8196 batches
[2025-05-21 03:22:10.435515]: text loss 0.6856 | 77800/ 8196 batches
[2025-05-21 03:23:50.512379]: text loss 0.6850 | 78000/ 8196 batches
[2025-05-21 03:25:28.975367]: text loss 0.6805 | 78200/ 8196 batches
[2025-05-21 03:27:07.707420]: text loss 0.6957 | 78400/ 8196 batches
[2025-05-21 03:28:45.440631]: text loss 0.6832 | 78600/ 8196 batches
[2025-05-21 03:30:23.272140]: text loss 0.6871 | 78800/ 8196 batches
[2025-05-21 03:32:02.453571]: text loss 0.6868 | 79000/ 8196 batches
[2025-05-21 03:33:41.701744]: text loss 0.6876 | 79200/ 8196 batches
[2025-05-21 03:35:21.601653]: text loss 0.6897 | 79400/ 8196 batches
[2025-05-21 03:36:58.588896]: text loss 0.6853 | 79600/ 8196 batches
[2025-05-21 03:38:35.945282]: text loss 0.6863 | 79800/ 8196 batches
[2025-05-21 03:40:14.030218]: text loss 0.6821 | 80000/ 8196 batches
[2025-05-21 03:41:50.693702]: text loss 0.6930 | 80200/ 8196 batches
[2025-05-21 03:43:28.117709]: text loss 0.6903 | 80400/ 8196 batches
[2025-05-21 03:45:05.569209]: text loss 0.6825 | 80600/ 8196 batches
[2025-05-21 03:46:44.827123]: text loss 0.6813 | 80800/ 8196 batches
[2025-05-21 03:48:24.203490]: text loss 0.6874 | 81000/ 8196 batches
[2025-05-21 03:50:01.943211]: text loss 0.6882 | 81200/ 8196 batches
[2025-05-21 03:51:40.293205]: text loss 0.6904 | 81400/ 8196 batches
[2025-05-21 03:53:18.240414]: text loss 0.6824 | 81600/ 8196 batches
[2025-05-21 03:54:56.145310]: text loss 0.6882 | 81800/ 8196 batches
[2025-05-21 03:56:14.599109]: text loss 0.6929 | 81960/ 8196 batches
[2025-05-21 03:56:14.599766]: validation
[2025-05-21 03:56:16.774338]: explanation loss 2.1451
[2025-05-21 03:56:20.695128]: rationale loss 1.0346
[2025-05-21 03:56:29.803807]: sequential loss 2.2947
[2025-05-21 03:57:27.990684]: top-N loss 1.2289
[2025-05-21 03:57:27.990774]: Endured 2 time(s)
[2025-05-21 03:57:27.990802]: epoch 11
[2025-05-21 03:57:47.315559]: text loss 0.6891 | 82000/ 8196 batches
[2025-05-21 03:59:23.650182]: text loss 0.6691 | 82200/ 8196 batches
[2025-05-21 04:01:01.625379]: text loss 0.6766 | 82400/ 8196 batches
[2025-05-21 04:02:38.564466]: text loss 0.6756 | 82600/ 8196 batches
[2025-05-21 04:04:15.366714]: text loss 0.6658 | 82800/ 8196 batches
[2025-05-21 04:05:51.836830]: text loss 0.6774 | 83000/ 8196 batches
[2025-05-21 04:07:28.392494]: text loss 0.6792 | 83200/ 8196 batches
[2025-05-21 04:09:05.222433]: text loss 0.6800 | 83400/ 8196 batches
[2025-05-21 04:10:42.369175]: text loss 0.6817 | 83600/ 8196 batches
[2025-05-21 04:12:20.117488]: text loss 0.6711 | 83800/ 8196 batches
[2025-05-21 04:13:58.492052]: text loss 0.6784 | 84000/ 8196 batches
[2025-05-21 04:15:37.528685]: text loss 0.6679 | 84200/ 8196 batches
[2025-05-21 04:17:15.176312]: text loss 0.6755 | 84400/ 8196 batches
[2025-05-21 04:18:53.804510]: text loss 0.6778 | 84600/ 8196 batches
[2025-05-21 04:20:30.687937]: text loss 0.6812 | 84800/ 8196 batches
[2025-05-21 04:22:10.426726]: text loss 0.6711 | 85000/ 8196 batches
[2025-05-21 04:23:49.445610]: text loss 0.6748 | 85200/ 8196 batches
[2025-05-21 04:25:28.286502]: text loss 0.6742 | 85400/ 8196 batches
[2025-05-21 04:27:07.543376]: text loss 0.6808 | 85600/ 8196 batches
[2025-05-21 04:28:46.593998]: text loss 0.6750 | 85800/ 8196 batches
[2025-05-21 04:30:25.387603]: text loss 0.6704 | 86000/ 8196 batches
[2025-05-21 04:32:02.232378]: text loss 0.6701 | 86200/ 8196 batches
[2025-05-21 04:33:40.821459]: text loss 0.6852 | 86400/ 8196 batches
[2025-05-21 04:35:20.220794]: text loss 0.6798 | 86600/ 8196 batches
[2025-05-21 04:36:57.633948]: text loss 0.6849 | 86800/ 8196 batches
[2025-05-21 04:38:34.652308]: text loss 0.6818 | 87000/ 8196 batches
[2025-05-21 04:40:11.303459]: text loss 0.6793 | 87200/ 8196 batches
[2025-05-21 04:41:48.294396]: text loss 0.6749 | 87400/ 8196 batches
[2025-05-21 04:43:25.361968]: text loss 0.6799 | 87600/ 8196 batches
[2025-05-21 04:45:03.418601]: text loss 0.6849 | 87800/ 8196 batches
[2025-05-21 04:46:40.526408]: text loss 0.6794 | 88000/ 8196 batches
[2025-05-21 04:48:19.619953]: text loss 0.6752 | 88200/ 8196 batches
[2025-05-21 04:49:57.900058]: text loss 0.6749 | 88400/ 8196 batches
[2025-05-21 04:51:35.755429]: text loss 0.6765 | 88600/ 8196 batches
[2025-05-21 04:53:12.731652]: text loss 0.6790 | 88800/ 8196 batches
[2025-05-21 04:54:49.575168]: text loss 0.6752 | 89000/ 8196 batches
[2025-05-21 04:56:26.738209]: text loss 0.6793 | 89200/ 8196 batches
[2025-05-21 04:58:03.589398]: text loss 0.6829 | 89400/ 8196 batches
[2025-05-21 04:59:41.919744]: text loss 0.6776 | 89600/ 8196 batches
[2025-05-21 05:01:19.028176]: text loss 0.6826 | 89800/ 8196 batches
[2025-05-21 05:02:56.046844]: text loss 0.6759 | 90000/ 8196 batches
[2025-05-21 05:04:11.691540]: text loss 0.6881 | 90156/ 8196 batches
[2025-05-21 05:04:11.692389]: validation
[2025-05-21 05:04:13.889227]: explanation loss 2.1469
[2025-05-21 05:04:17.812350]: rationale loss 1.0338
[2025-05-21 05:04:26.812522]: sequential loss 2.3077
[2025-05-21 05:05:24.586423]: top-N loss 1.2330
[2025-05-21 05:05:24.586512]: Endured 3 time(s)
[2025-05-21 05:05:24.586537]: epoch 12
[2025-05-21 05:05:45.786466]: text loss 0.6697 | 90200/ 8196 batches
[2025-05-21 05:07:22.173880]: text loss 0.6684 | 90400/ 8196 batches
[2025-05-21 05:08:58.958771]: text loss 0.6647 | 90600/ 8196 batches
[2025-05-21 05:10:37.569576]: text loss 0.6655 | 90800/ 8196 batches
[2025-05-21 05:12:15.520424]: text loss 0.6621 | 91000/ 8196 batches
[2025-05-21 05:13:54.515967]: text loss 0.6650 | 91200/ 8196 batches
[2025-05-21 05:15:33.368089]: text loss 0.6670 | 91400/ 8196 batches
[2025-05-21 05:17:10.258710]: text loss 0.6653 | 91600/ 8196 batches
[2025-05-21 05:18:47.176624]: text loss 0.6645 | 91800/ 8196 batches
[2025-05-21 05:20:23.903462]: text loss 0.6631 | 92000/ 8196 batches
[2025-05-21 05:22:02.295001]: text loss 0.6617 | 92200/ 8196 batches
[2025-05-21 05:23:41.331908]: text loss 0.6680 | 92400/ 8196 batches
[2025-05-21 05:25:20.009313]: text loss 0.6640 | 92600/ 8196 batches
[2025-05-21 05:26:59.047675]: text loss 0.6655 | 92800/ 8196 batches
[2025-05-21 05:28:37.316969]: text loss 0.6663 | 93000/ 8196 batches
[2025-05-21 05:30:14.133022]: text loss 0.6666 | 93200/ 8196 batches
[2025-05-21 05:31:51.270106]: text loss 0.6622 | 93400/ 8196 batches
[2025-05-21 05:33:27.901347]: text loss 0.6656 | 93600/ 8196 batches
[2025-05-21 05:35:04.573917]: text loss 0.6683 | 93800/ 8196 batches
[2025-05-21 05:36:41.257554]: text loss 0.6631 | 94000/ 8196 batches
[2025-05-21 05:38:18.636391]: text loss 0.6649 | 94200/ 8196 batches
[2025-05-21 05:39:57.140793]: text loss 0.6643 | 94400/ 8196 batches
[2025-05-21 05:41:35.828898]: text loss 0.6740 | 94600/ 8196 batches
[2025-05-21 05:43:14.937159]: text loss 0.6704 | 94800/ 8196 batches
[2025-05-21 05:44:53.670726]: text loss 0.6713 | 95000/ 8196 batches
[2025-05-21 05:46:30.646703]: text loss 0.6645 | 95200/ 8196 batches
[2025-05-21 05:48:09.892106]: text loss 0.6715 | 95400/ 8196 batches
[2025-05-21 05:49:48.872717]: text loss 0.6700 | 95600/ 8196 batches
[2025-05-21 05:51:26.405588]: text loss 0.6704 | 95800/ 8196 batches
[2025-05-21 05:53:04.892571]: text loss 0.6704 | 96000/ 8196 batches
[2025-05-21 05:54:42.529879]: text loss 0.6751 | 96200/ 8196 batches
[2025-05-21 05:56:19.350015]: text loss 0.6710 | 96400/ 8196 batches
[2025-05-21 05:57:58.581512]: text loss 0.6697 | 96600/ 8196 batches
[2025-05-21 05:59:37.541366]: text loss 0.6709 | 96800/ 8196 batches
[2025-05-21 06:01:16.655552]: text loss 0.6659 | 97000/ 8196 batches
[2025-05-21 06:02:54.621134]: text loss 0.6713 | 97200/ 8196 batches
[2025-05-21 06:04:32.423103]: text loss 0.6706 | 97400/ 8196 batches
[2025-05-21 06:06:09.816742]: text loss 0.6783 | 97600/ 8196 batches
[2025-05-21 06:07:47.611914]: text loss 0.6699 | 97800/ 8196 batches
[2025-05-21 06:09:26.084741]: text loss 0.6764 | 98000/ 8196 batches
[2025-05-21 06:11:02.833402]: text loss 0.6762 | 98200/ 8196 batches
[2025-05-21 06:12:17.529249]: text loss 0.6673 | 98352/ 8196 batches
[2025-05-21 06:12:17.529916]: validation
[2025-05-21 06:12:19.735270]: explanation loss 2.1559
[2025-05-21 06:12:23.662894]: rationale loss 1.0280
[2025-05-21 06:12:32.677935]: sequential loss 2.3112
[2025-05-21 06:13:30.456691]: top-N loss 1.2434
[2025-05-21 06:13:30.456789]: Endured 4 time(s)
[2025-05-21 06:13:30.456817]: epoch 13
[2025-05-21 06:13:53.625777]: text loss 0.6641 | 98400/ 8196 batches
[2025-05-21 06:15:30.720160]: text loss 0.6481 | 98600/ 8196 batches
[2025-05-21 06:17:08.324731]: text loss 0.6569 | 98800/ 8196 batches
[2025-05-21 06:18:46.233770]: text loss 0.6569 | 99000/ 8196 batches
[2025-05-21 06:20:25.131943]: text loss 0.6553 | 99200/ 8196 batches
[2025-05-21 06:22:04.006840]: text loss 0.6565 | 99400/ 8196 batches
[2025-05-21 06:23:42.447519]: text loss 0.6603 | 99600/ 8196 batches
[2025-05-21 06:25:19.542811]: text loss 0.6538 | 99800/ 8196 batches
[2025-05-21 06:26:58.449310]: text loss 0.6577 | 100000/ 8196 batches
[2025-05-21 06:28:36.597416]: text loss 0.6592 | 100200/ 8196 batches
[2025-05-21 06:30:13.501246]: text loss 0.6663 | 100400/ 8196 batches
[2025-05-21 06:31:50.669147]: text loss 0.6533 | 100600/ 8196 batches
[2025-05-21 06:33:27.529667]: text loss 0.6551 | 100800/ 8196 batches
[2025-05-21 06:35:04.210120]: text loss 0.6624 | 101000/ 8196 batches
[2025-05-21 06:36:41.267658]: text loss 0.6613 | 101200/ 8196 batches
[2025-05-21 06:38:18.198721]: text loss 0.6558 | 101400/ 8196 batches
[2025-05-21 06:39:55.230667]: text loss 0.6570 | 101600/ 8196 batches
[2025-05-21 06:41:32.248982]: text loss 0.6494 | 101800/ 8196 batches
[2025-05-21 06:43:09.134613]: text loss 0.6574 | 102000/ 8196 batches
[2025-05-21 06:44:46.976129]: text loss 0.6606 | 102200/ 8196 batches
[2025-05-21 06:46:26.034879]: text loss 0.6665 | 102400/ 8196 batches
[2025-05-21 06:48:04.386315]: text loss 0.6577 | 102600/ 8196 batches
[2025-05-21 06:49:43.567053]: text loss 0.6545 | 102800/ 8196 batches
[2025-05-21 06:51:20.654768]: text loss 0.6563 | 103000/ 8196 batches
[2025-05-21 06:52:59.198473]: text loss 0.6606 | 103200/ 8196 batches
[2025-05-21 06:54:36.187628]: text loss 0.6678 | 103400/ 8196 batches
[2025-05-21 06:56:14.887412]: text loss 0.6491 | 103600/ 8196 batches
[2025-05-21 06:57:52.554870]: text loss 0.6608 | 103800/ 8196 batches
[2025-05-21 06:59:30.438996]: text loss 0.6595 | 104000/ 8196 batches
[2025-05-21 07:01:08.838748]: text loss 0.6620 | 104200/ 8196 batches
[2025-05-21 07:02:46.497784]: text loss 0.6582 | 104400/ 8196 batches
[2025-05-21 07:04:24.320289]: text loss 0.6639 | 104600/ 8196 batches
[2025-05-21 07:06:03.388826]: text loss 0.6523 | 104800/ 8196 batches
[2025-05-21 07:07:41.317608]: text loss 0.6622 | 105000/ 8196 batches
[2025-05-21 07:09:17.572277]: text loss 0.6539 | 105200/ 8196 batches
[2025-05-21 07:10:55.040960]: text loss 0.6664 | 105400/ 8196 batches
[2025-05-21 07:12:34.368280]: text loss 0.6568 | 105600/ 8196 batches
[2025-05-21 07:14:13.510065]: text loss 0.6596 | 105800/ 8196 batches
[2025-05-21 07:15:52.670594]: text loss 0.6616 | 106000/ 8196 batches
[2025-05-21 07:17:30.141070]: text loss 0.6545 | 106200/ 8196 batches
[2025-05-21 07:19:06.747203]: text loss 0.6565 | 106400/ 8196 batches
[2025-05-21 07:20:18.836695]: text loss 0.6588 | 106548/ 8196 batches
[2025-05-21 07:20:18.837228]: validation
[2025-05-21 07:20:20.997684]: explanation loss 2.1613
[2025-05-21 07:20:24.922338]: rationale loss 1.0285
[2025-05-21 07:20:33.936013]: sequential loss 2.3611
[2025-05-21 07:21:31.597304]: top-N loss 1.2678
[2025-05-21 07:21:31.597392]: Endured 5 time(s)
[2025-05-21 07:21:31.597415]: Cannot endure it anymore | Exiting from early stop
